{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b0ec85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/MLX_Week2/mlx_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnnamdi-odozi\u001b[0m (\u001b[33mnnamdi-odozi-ave-actuaries\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from load_models_and_data import load_vocabulary, load_embeddings, text_to_embeddings, calc_cosine_sim, calculate_embeddings, create_packed_batch\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "#from TwoTowerNN import QryTower, DocTower, TripletEmbeddingDataset, run_hyperparameter_tuning\n",
    "from TwinTowerGRU import QryTower, DocTower, EmbeddingTripletDataset, run_hyperparameter_tuning\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader,  SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import os\n",
    "import wandb\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d86a222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b860fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba466e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Loading datasets from Hugging Face\n",
    "ds_soft_neg = load_dataset(\"cocoritzy/week_2_triplet_dataset_soft_negatives\")\n",
    "ds_hard_neg = load_dataset(\"cocoritzy/week_2_triplet_dataset_hard_negatives\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a1948ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings and vocabulary...\n",
      "Loaded embeddings with shape: torch.Size([400000, 100])\n",
      "Loaded vocabulary with 399998 tokens\n",
      "Embedded text shape: torch.Size([26, 100])\n",
      "Embedding array with custom formatting:\n",
      "[[ 0.2616  0.4472 -0.0968 ... -0.4503  0.4952 -0.203 ]\n",
      " [ 0.1372 -0.5429  0.1942 ... -0.5206  0.2543 -0.2376]\n",
      " [-0.3046 -0.2365  0.1758 ... -0.8456 -0.0354  0.1704]\n",
      " ...\n",
      " [ 0.      0.      0.     ...  0.      0.      0.    ]\n",
      " [ 0.      0.      0.     ...  0.      0.      0.    ]\n",
      " [ 0.      0.      0.     ...  0.      0.      0.    ]]\n",
      "Length is: 5\n"
     ]
    }
   ],
   "source": [
    "# Paths to your files\n",
    "embeddings_path = \"./downloaded_model/glove_embeddings.pt\" #set this to either own-trained cbow ones or to glove pre-trained ones\n",
    "vocab_path = \"./downloaded_model/glove_ids_to_words.csv\"\n",
    "\n",
    "# Load embeddings and vocabulary\n",
    "print(\"Loading embeddings and vocabulary...\")\n",
    "embeddings = load_embeddings(embeddings_path)\n",
    "word_to_idx = load_vocabulary(vocab_path)\n",
    "\n",
    "print(f\"Loaded embeddings with shape: {embeddings.shape}\")\n",
    "print(f\"Loaded vocabulary with {len(word_to_idx)} tokens\")\n",
    "\n",
    "# Example usage (uncomment when ready to test)\n",
    "sample_text = \"This is a test sentence\"\n",
    "embeddings_result, length = text_to_embeddings(sample_text, word_to_idx, embeddings, is_query=True)\n",
    "print(f\"Embedded text shape: {embeddings_result.shape}\")\n",
    "\n",
    "# Testing - Set numpy print options\n",
    "np.set_printoptions(precision=4, suppress=True, threshold=10)  # threshold limits number of elements shown\n",
    "numpy_array = embeddings_result.detach().numpy()\n",
    "print(\"Embedding array with custom formatting:\")\n",
    "print(numpy_array)\n",
    "print(\"Length is:\", length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff426027",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\n",
    "embeddings_result, length = text_to_embeddings(sample_text, word_to_idx, embeddings, is_query=True)\n",
    "print(f\"Embedded text shape: {embeddings_result.shape}\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True, threshold=10)  # threshold limits number of elements shown\n",
    "numpy_array = embeddings_result.detach().numpy()\n",
    "print(\"Embedding array with custom formatting:\")\n",
    "print(numpy_array)\n",
    "print(\"Length is:\", length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a28244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soft_neg  = pd.DataFrame(ds_soft_neg['train'])\n",
    "df_hard_neg  = pd.DataFrame(ds_hard_neg['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b81dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_query, length = text_to_embeddings(df_soft_neg['query'][0], word_to_idx, embeddings, is_query=True)\n",
    "embedded_positive, length = text_to_embeddings(df_soft_neg['positive_passage'][0], word_to_idx, embeddings, is_query=False)\n",
    "embedded_negative, length = text_to_embeddings(df_soft_neg['negative_passage'][0], word_to_idx, embeddings, is_query=False)\n",
    "\n",
    "print(embedded_positive.shape)\n",
    "print(embedded_negative.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = embedded_query.mean(dim=0)\n",
    "b = embedded_positive.mean(dim=0)\n",
    "c = embedded_negative.mean(dim=0)\n",
    "a.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "cosine_similarity = F.cosine_similarity(a, c, dim=0)\n",
    "print(f\"Cosine similarity between query and positive passage: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Process the dataframe using apply just for first five rows\n",
    "# print(\"Calculating similarities... This may take a while depending on dataframe size.\")\n",
    "# similarities = df_soft_neg[0:5].progress_apply(\n",
    "#     lambda row: calculate_similarities(row, word_to_idx, embeddings), \n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # Join the similarities to the dataframe\n",
    "# df_soft_neg_ext = pd.concat([df_soft_neg[0:5], similarities], axis=1)\n",
    "\n",
    "# # Show a sample of the results\n",
    "# #print(df_soft_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].head())\n",
    "#print(df_soft_neg_ext.head())\n",
    "#print(df_soft_neg_ext.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a02f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process the dataframe using apply\n",
    "print(\"Calculating embeddings... This may take a while depending on dataframe size.\")\n",
    "embeddings_padded = df_soft_neg.progress_apply(\n",
    "    lambda row: calculate_embeddings(row, word_to_idx, embeddings), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Join the similarities to the dataframe\n",
    "df_soft_neg_ext = pd.concat([df_soft_neg, embeddings_padded], axis=1)\n",
    "print(df_soft_neg_ext.head())\n",
    "# Show a sample of the results\n",
    "#print(df_soft_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].head())\n",
    "\n",
    "#print(df_soft_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].mean())\n",
    "\n",
    "# Calculate how often the positive passage is ranked higher than negative\n",
    "#higher_count = (df_soft_neg_ext['query_pos_sim'] > df_soft_neg_ext['query_neg_sim']).sum()\n",
    "#total = len(df_soft_neg_ext)\n",
    "#print(f\"\\nPositive passage ranked higher than negative: {higher_count} out of {total} ({higher_count/total:.2%})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soft_neg_ext[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbbd3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the dataframe using apply\n",
    "print(\"Calculating embeddings... This may take a while depending on dataframe size.\")\n",
    "embeddings_padded = df_hard_neg.progress_apply(\n",
    "    lambda row: calculate_embeddings(row, word_to_idx, embeddings), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Join the similarities to the dataframe\n",
    "df_hard_neg_ext = pd.concat([df_hard_neg, embeddings_padded], axis=1)\n",
    "print(df_hard_neg_ext.head())\n",
    "# Show a sample of the results\n",
    "#print(df_hard_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].head())\n",
    "\n",
    "#print(df_hard_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].mean())\n",
    "\n",
    "# Calculate how often the positive passage is ranked higher than negative\n",
    "#higher_count = (df_hard_neg_ext['query_pos_sim'] > df_hard_neg_ext['query_neg_sim']).sum()\n",
    "#total = len(df_hard_neg_ext)\n",
    "#print(f\"\\nPositive passage ranked higher than negative: {higher_count} out of {total} ({higher_count/total:.2%})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cea888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_neg_ext = pd.concat([df_soft_neg_ext, df_hard_neg_ext])\n",
    "df_all_neg_ext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766f3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrames to pickle format\n",
    "df_soft_neg_ext.to_pickle(\"downloaded_model/df_soft_neg_ext.pkl\")\n",
    "df_hard_neg_ext.to_pickle(\"downloaded_model/df_hard_neg_ext.pkl\")\n",
    "df_all_neg_ext.to_pickle(\"downloaded_model/df_all_neg_ext.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02765d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a DataFrame from pickle if the file exists\n",
    "def load_df_if_exists(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        return pd.read_pickle(file_path)\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "# Load DataFrames\n",
    "df_soft_neg_ext = load_df_if_exists(\"downloaded_model/df_soft_neg_ext.pkl\")\n",
    "#df_hard_neg_ext = load_df_if_exists(\"downloaded_model/df_hard_neg_ext.pkl\")\n",
    "#df_all_neg_ext = load_df_if_exists(\"downloaded_model/df_all_neg_ext.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b9f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soft_neg_ext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Create packed sequences for RNN processing\n",
    "#packed_queries, packed_positives, packed_negatives = create_packed_batch(df_all_neg_ext)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd683001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Feed packed sequences to your RNN models\n",
    "# query_outputs, query_hidden =your_query_rnn(packed_queries)\n",
    "# pos_outputs, pos_hidden = your_document_rnn(packed_positives)\n",
    "# neg_outputs, neg_hidden = your_document_rnn(packed_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e0660e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/MLX_Week2/wandb/run-20250424_174424-x5ie5g41</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/x5ie5g41' target=\"_blank\">hyperparameter-tuning-20250424-174424</a></strong> to <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/x5ie5g41' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/x5ie5g41</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splits: Train=47822 | Validation=15941 | Test=15941\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hyperparameter-tuning-20250424-174424</strong> at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/x5ie5g41' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/x5ie5g41</a><br> View project at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_174424-x5ie5g41/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/MLX_Week2/wandb/run-20250424_174424-bqyxg7ch</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/bqyxg7ch' target=\"_blank\">dim100_batch512_hidden100_layers1_20250424-174424</a></strong> to <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/bqyxg7ch' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/bqyxg7ch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/MLX_Week2/mlx_env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training with: output_dim=100, batch_size=512, gru_hidden_dim=100, num_layers=1, dropout=0.1, lr=0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 10.82it/s]\n",
      "Epoch 1/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.1607, Val Loss: 0.1335, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 11.07it/s]\n",
      "Epoch 2/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.1218, Val Loss: 0.1128, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 11.72it/s]\n",
      "Epoch 3/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.0970, Val Loss: 0.0973, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 11.35it/s]\n",
      "Epoch 4/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.0798, Val Loss: 0.0867, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 11.19it/s]\n",
      "Epoch 5/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.0691, Val Loss: 0.0821, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 11.38it/s]\n",
      "Epoch 6/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.0587, Val Loss: 0.0774, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 11.47it/s]\n",
      "Epoch 7/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.0517, Val Loss: 0.0757, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 10.89it/s]\n",
      "Epoch 8/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.0445, Val Loss: 0.0719, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 11.64it/s]\n",
      "Epoch 9/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0392, Val Loss: 0.0731, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 10.59it/s]\n",
      "Epoch 10/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0346, Val Loss: 0.0729, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▄▄▃▂▂▂▁▁</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_loss</td><td>0.03456</td></tr><tr><td>val_loss</td><td>0.0729</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dim100_batch512_hidden100_layers1_20250424-174424</strong> at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/bqyxg7ch' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/bqyxg7ch</a><br> View project at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_174424-bqyxg7ch/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/MLX_Week2/wandb/run-20250424_174630-iuga6o12</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/iuga6o12' target=\"_blank\">dim100_batch512_hidden200_layers1_20250424-174424</a></strong> to <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/iuga6o12' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/iuga6o12</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/MLX_Week2/mlx_env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training with: output_dim=100, batch_size=512, gru_hidden_dim=200, num_layers=1, dropout=0.1, lr=0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Train): 100%|██████████| 94/94 [00:11<00:00,  8.10it/s]\n",
      "Epoch 1/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.1596, Val Loss: 0.1489, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 (Train): 100%|██████████| 94/94 [00:11<00:00,  7.99it/s]\n",
      "Epoch 2/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.1280, Val Loss: 0.1193, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 (Train): 100%|██████████| 94/94 [00:11<00:00,  8.24it/s]\n",
      "Epoch 3/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.1065, Val Loss: 0.1006, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 (Train): 100%|██████████| 94/94 [00:11<00:00,  8.12it/s]\n",
      "Epoch 4/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.0892, Val Loss: 0.0908, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 (Train): 100%|██████████| 94/94 [00:11<00:00,  8.21it/s]\n",
      "Epoch 5/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.0777, Val Loss: 0.0862, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 (Train): 100%|██████████| 94/94 [00:11<00:00,  8.26it/s]\n",
      "Epoch 6/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.0665, Val Loss: 0.0844, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 (Train): 100%|██████████| 94/94 [00:12<00:00,  7.45it/s]\n",
      "Epoch 7/10 (Val): 100%|██████████| 32/32 [00:05<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.0593, Val Loss: 0.0799, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 (Train): 100%|██████████| 94/94 [00:13<00:00,  7.20it/s]\n",
      "Epoch 8/10 (Val): 100%|██████████| 32/32 [00:05<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.0513, Val Loss: 0.0786, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 (Train): 100%|██████████| 94/94 [00:14<00:00,  6.63it/s]\n",
      "Epoch 9/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0449, Val Loss: 0.0797, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 (Train): 100%|██████████| 94/94 [00:10<00:00,  8.84it/s]\n",
      "Epoch 10/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0391, Val Loss: 0.0775, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_loss</td><td>0.03914</td></tr><tr><td>val_loss</td><td>0.07751</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dim100_batch512_hidden200_layers1_20250424-174424</strong> at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/iuga6o12' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/iuga6o12</a><br> View project at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_174630-iuga6o12/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/MLX_Week2/wandb/run-20250424_174919-ayo3imz6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ayo3imz6' target=\"_blank\">dim100_batch1024_hidden100_layers1_20250424-174424</a></strong> to <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ayo3imz6' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ayo3imz6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/MLX_Week2/mlx_env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training with: output_dim=100, batch_size=1024, gru_hidden_dim=100, num_layers=1, dropout=0.1, lr=0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.59it/s]\n",
      "Epoch 1/10 (Val): 100%|██████████| 16/16 [00:04<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.1750, Val Loss: 0.1490, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.00it/s]\n",
      "Epoch 2/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.1372, Val Loss: 0.1300, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.56it/s]\n",
      "Epoch 3/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.1200, Val Loss: 0.1196, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.20it/s]\n",
      "Epoch 4/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.1048, Val Loss: 0.1049, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.63it/s]\n",
      "Epoch 5/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.0900, Val Loss: 0.0983, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.56it/s]\n",
      "Epoch 6/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.0802, Val Loss: 0.0899, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.28it/s]\n",
      "Epoch 7/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.0714, Val Loss: 0.0868, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.58it/s]\n",
      "Epoch 8/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.0638, Val Loss: 0.0831, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.59it/s]\n",
      "Epoch 9/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0569, Val Loss: 0.0839, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.58it/s]\n",
      "Epoch 10/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0512, Val Loss: 0.0793, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_loss</td><td>0.05122</td></tr><tr><td>val_loss</td><td>0.07929</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dim100_batch1024_hidden100_layers1_20250424-174424</strong> at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ayo3imz6' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ayo3imz6</a><br> View project at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_174919-ayo3imz6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/MLX_Week2/wandb/run-20250424_175113-teeomm0j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/teeomm0j' target=\"_blank\">dim100_batch1024_hidden200_layers1_20250424-174424</a></strong> to <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/teeomm0j' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/teeomm0j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/MLX_Week2/mlx_env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training with: output_dim=100, batch_size=1024, gru_hidden_dim=200, num_layers=1, dropout=0.1, lr=0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.42it/s]\n",
      "Epoch 1/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.1720, Val Loss: 0.1511, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.47it/s]\n",
      "Epoch 2/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.1487, Val Loss: 0.1393, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.48it/s]\n",
      "Epoch 3/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.1343, Val Loss: 0.1313, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.62it/s]\n",
      "Epoch 4/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.1297, Val Loss: 0.1269, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.54it/s]\n",
      "Epoch 5/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.1269, Val Loss: 0.1228, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.51it/s]\n",
      "Epoch 6/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.1151, Val Loss: 0.1174, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.52it/s]\n",
      "Epoch 7/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.1097, Val Loss: 0.1073, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.61it/s]\n",
      "Epoch 8/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.1002, Val Loss: 0.1003, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.55it/s]\n",
      "Epoch 9/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0948, Val Loss: 0.1016, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.55it/s]\n",
      "Epoch 10/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0888, Val Loss: 0.0982, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▂▂▁</td></tr><tr><td>val_loss</td><td>█▆▅▅▄▄▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_loss</td><td>0.08883</td></tr><tr><td>val_loss</td><td>0.09819</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dim100_batch1024_hidden200_layers1_20250424-174424</strong> at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/teeomm0j' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/teeomm0j</a><br> View project at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_175113-teeomm0j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best hyperparameters:\n",
      "Output dimension: 100\n",
      "Batch size: 512\n",
      "GRU hidden dimension: 100\n",
      "Number of GRU layers: 1\n",
      "Dropout: 0.1\n",
      "Learning rate: 0.001\n",
      "Validation Loss: 0.0719\n",
      "\n",
      "\n",
      "Training final model with best hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 11.69it/s]\n",
      "Epoch 1/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.1546, Val Loss: 0.1295, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 (Train): 100%|██████████| 125/125 [00:09<00:00, 12.63it/s]\n",
      "Epoch 2/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.1176, Val Loss: 0.1054, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.47it/s]\n",
      "Epoch 3/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.0938, Val Loss: 0.0884, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.37it/s]\n",
      "Epoch 4/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.0780, Val Loss: 0.0792, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.37it/s]\n",
      "Epoch 5/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.0676, Val Loss: 0.0753, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.33it/s]\n",
      "Epoch 6/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.0587, Val Loss: 0.0707, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.26it/s]\n",
      "Epoch 7/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.0524, Val Loss: 0.0669, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.14it/s]\n",
      "Epoch 8/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.0452, Val Loss: 0.0656, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.48it/s]\n",
      "Epoch 9/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0392, Val Loss: 0.0651, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.45it/s]\n",
      "Epoch 10/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0346, Val Loss: 0.0636, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0636\n",
      "Final model saved at: checkpoints/final_gru_model_20250424-174424/final_gru_model_20250424-174424.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/MLX_Week2/wandb/run-20250424_175537-ru8xhh4d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ru8xhh4d' target=\"_blank\">final_model_20250424-174424</a></strong> to <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ru8xhh4d' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ru8xhh4d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">final_model_20250424-174424</strong> at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ru8xhh4d' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ru8xhh4d</a><br> View project at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_175537-ru8xhh4d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'output_dim': 100,\n",
       "  'batch_size': 512,\n",
       "  'gru_hidden_dim': 100,\n",
       "  'num_layers': 1,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.001,\n",
       "  'val_loss': 0.07193102573929298},\n",
       " GRUTwinTowerModel(\n",
       "   (query_encoder): BidirectionalGRU(\n",
       "     (gru): GRU(100, 100, batch_first=True, bidirectional=True)\n",
       "   )\n",
       "   (doc_encoder): BidirectionalGRU(\n",
       "     (gru): GRU(100, 100, batch_first=True, bidirectional=True)\n",
       "   )\n",
       "   (query_tower): QryTower(\n",
       "     (fc1): Linear(in_features=200, out_features=128, bias=True)\n",
       "     (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "     (fc3): Linear(in_features=64, out_features=100, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (doc_tower): DocTower(\n",
       "     (fc1): Linear(in_features=200, out_features=128, bias=True)\n",
       "     (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "     (fc3): Linear(in_features=64, out_features=100, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hyperparameter_tuning(df_soft_neg_ext, output_dims=[100], batch_sizes=[512, 1024], gru_hidden_dims=[100,200], \n",
    "                         num_layers=[1], dropouts=[0.1], learning_rates=[1e-3], \n",
    "                         epochs=10, log_wandb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba3edcd",
   "metadata": {},
   "source": [
    "### Twin Tower Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05391efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239cc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tower instances\n",
    "#qryTower = QryTower()\n",
    "#docTower = DocTower()\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 128\n",
    "num_epochs = 1 # adjust num of epochs here\n",
    "dataset_size = len(df_all_neg_ext)  # or len(df_hard_neg_ext) depending on the dataset you want to use\n",
    "steps_per_epoch = dataset_size // batch_size\n",
    "total_steps = steps_per_epoch * num_epochs\n",
    "learning_rate = 1e-3\n",
    "embedding_dim = 100 #changed for glove \n",
    "margin = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = TripletEmbeddingDataset(df_all_neg_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7753f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    #num_workers=2,  # Adjust based on your machine's capabilities\n",
    "    pin_memory=True  # Set to True if using GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = torch.randn(batch_size, embedding_dim)  # Query embeddings\n",
    "pos = torch.randn(batch_size, embedding_dim)  # Positive doc embeddings\n",
    "neg = torch.randn(batch_size, embedding_dim)  # Negative doc embeddings\n",
    "\n",
    "#qry = df1['q']\n",
    "\n",
    "\n",
    "# Set up the AdamW optimizer\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': qryTower.parameters()},\n",
    "    {'params': docTower.parameters()}\n",
    "], lr=learning_rate)\n",
    "\n",
    "# Add learning rate scheduler (ReduceLROnPlateau)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',       # Reduce LR when monitored value stops decreasing\n",
    "    factor=0.5,       # Multiply LR by this factor when reducing\n",
    "    patience=2,       # Number of epochs with no improvement after which LR will be reduced\n",
    "    verbose=True      # Print message when LR is reduced\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aedf0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (simplified example)\n",
    "for epoch in range(num_epochs):\n",
    "    qryTower.train()\n",
    "    docTower.train()\n",
    "    \n",
    "    \n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        # Get embeddings from batch\n",
    "        query_emb = batch['query']\n",
    "        pos_emb = batch['positive']\n",
    "        neg_emb = batch['negative']\n",
    "        \n",
    "        # Forward pass through towers\n",
    "        query_encoded = qryTower(query_emb)\n",
    "        pos_encoded = docTower(pos_emb)\n",
    "        neg_encoded = docTower(neg_emb)\n",
    "        \n",
    "        # Calculate similarities\n",
    "        pos_sim = torch.nn.functional.cosine_similarity(query_encoded, pos_encoded)\n",
    "        neg_sim = torch.nn.functional.cosine_similarity(query_encoded, neg_encoded)\n",
    "        \n",
    "        # Triplet loss\n",
    "        margin = margin\n",
    "        loss = torch.clamp(margin - pos_sim + neg_sim, min=0).mean()\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * len(query_emb)\n",
    "    \n",
    "    # Calculate average loss\n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, \"\n",
    "          f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb07bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the hyperparameter tuning with your dataframe\n",
    "best_params, final_qry_tower, final_doc_tower = run_hyperparameter_tuning(\n",
    "    df_all_neg_ext,\n",
    "    output_dims=[100],\n",
    "    batch_sizes=[512],\n",
    "    epochs=7\n",
    ")\n",
    "\n",
    "# Print the best parameters found\n",
    "print(f\"Best output dimension: {best_params['output_dim']}\")\n",
    "print(f\"Best batch size: {best_params['batch_size']}\")\n",
    "print(f\"Best validation loss: {best_params['val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8531b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(qryTower, docTower, dataloader, device):\n",
    "    qryTower.eval()\n",
    "    docTower.eval()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        # Get embeddings from batch\n",
    "        query_emb = batch['query']\n",
    "        pos_emb = batch['positive']\n",
    "        neg_emb = batch['negative']\n",
    "        \n",
    "        # Forward pass through towers\n",
    "        query_encoded = qryTower(query_emb)\n",
    "        pos_encoded = docTower(pos_emb)\n",
    "        neg_encoded = docTower(neg_emb)\n",
    "        \n",
    "        # Calculate similarities\n",
    "        pos_sim = torch.nn.functional.cosine_similarity(query_encoded, pos_encoded)\n",
    "        neg_sim = torch.nn.functional.cosine_similarity(query_encoded, neg_encoded)\n",
    "\n",
    "        correct += (pos_sim > neg_sim).sum().item()\n",
    "        total += batch['query'].size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"Eval Accuracy (query closer to pos than neg): {acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "total_loss = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53907333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Epoch {epoch+1}, Avg Loss: {total_loss / len(dataloader):.4f}\")\n",
    "evaluate_model(final_qry_tower, final_doc_tower, dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_emb = text_to_embeddings(\"What is RBA\", word_to_idx, embeddings)\n",
    "pos_emb = text_to_embeddings(\"What is RBA\", word_to_idx, embeddings)\n",
    "\n",
    "# Ensure tensors have at least two dimensions before applying mean\n",
    "if query_emb.dim() == 1:\n",
    "\tquery_emb = query_emb.unsqueeze(0)\n",
    "if pos_emb.dim() == 1:\n",
    "\tpos_emb = pos_emb.unsqueeze(0)\n",
    "\n",
    "query_emb = query_emb.mean(dim=0)\n",
    "pos_emb = pos_emb.mean(dim=0)\n",
    "\n",
    "print(torch.nn.functional.cosine_similarity(query_emb, pos_emb, dim=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_qry_tower.eval()\n",
    "final_doc_tower.eval()\n",
    "query_encoded = final_qry_tower(query_emb)\n",
    "pos_encoded = final_doc_tower(pos_emb)\n",
    "torch.nn.functional.cosine_similarity(query_encoded, pos_encoded, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11581eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to upload final model to wandb\n",
    "import wandb\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load your API key from config.txt\n",
    "def load_api_key_from_config(config_path=\"config.txt\"):\n",
    "    try:\n",
    "        with open(config_path, \"r\") as f:\n",
    "            first_line = f.readline().strip()\n",
    "            if \"=\" in first_line:\n",
    "                api_key = first_line.split(\"=\")[1].strip()\n",
    "            else:\n",
    "                api_key = first_line\n",
    "        return api_key\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Config file not found at {config_path}\")\n",
    "        return None\n",
    "\n",
    "# Set up wandb - only set API key if wandb.run doesn't exist yet\n",
    "if wandb.run is None:\n",
    "    api_key = load_api_key_from_config()\n",
    "    if api_key:\n",
    "        os.environ[\"WANDB_API_KEY\"] = api_key\n",
    "        wandb.login()\n",
    "        print(\"Successfully logged in to Weights & Biases\")\n",
    "    else:\n",
    "        print(\"Failed to load API key\")\n",
    "\n",
    "# Check if there's an active run, only initialize if needed\n",
    "if wandb.run is None:\n",
    "    run = wandb.init(\n",
    "        project=\"twin-tower-model\",\n",
    "        name=\"final-model-summary\",  # Changed name to indicate this is a summary\n",
    "        config={\n",
    "            \"output_dim\": best_params[\"output_dim\"],\n",
    "            \"batch_size\": best_params[\"batch_size\"],\n",
    "            \"architecture\": \"Twin Tower Network\",\n",
    "            \"dataset\": \"MS MARCO\"\n",
    "        }\n",
    "    )\n",
    "else:\n",
    "    run = wandb.run\n",
    "    # Update the run with additional metadata if needed\n",
    "    run.config.update({\n",
    "        \"architecture\": \"Twin Tower Network\",\n",
    "        \"dataset\": \"MS MARCO\"\n",
    "    })\n",
    "\n",
    "# Upload the model with a timestamp to avoid conflicts\n",
    "timestamp2 = int(time.time())\n",
    "artifact_name = f\"twin-tower-final-model-{timestamp2}\"\n",
    "\n",
    "model_artifact = wandb.Artifact(\n",
    "    name=artifact_name, \n",
    "    type=\"model\",\n",
    "    description=\"Twin Tower model trained on full training data with optimal hyperparameters\"\n",
    ")\n",
    "\n",
    "final_model_path = f\"checkpoints/final_model/final_model.pt\"\n",
    "model_artifact.add_file(final_model_path)\n",
    "wandb.log_artifact(model_artifact)\n",
    "\n",
    "print(f\"Final model uploaded to Weights & Biases project: {run.project}\")\n",
    "\n",
    "# Only finish the run if we created it in this script\n",
    "if run.name == \"final-model-summary\":\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

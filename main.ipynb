{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0ec85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/MLX_Week2/mlx_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnnamdi-odozi\u001b[0m (\u001b[33mnnamdi-odozi-ave-actuaries\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from load_models_and_data import load_vocabulary, load_embeddings, text_to_embeddings, calc_cosine_sim, calculate_similarities\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from TwoTowerNN import QryTower, DocTower, TripletEmbeddingDataset, run_hyperparameter_tuning\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader,  SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import os\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b860fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba466e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Loading datasets from Hugging Face\n",
    "ds_soft_neg = load_dataset(\"cocoritzy/week_2_triplet_dataset_soft_negatives\")\n",
    "ds_hard_neg = load_dataset(\"cocoritzy/week_2_triplet_dataset_hard_negatives\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a1948ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings and vocabulary...\n",
      "Loaded embeddings with shape: torch.Size([63642, 128])\n",
      "Loaded vocabulary with 63641 tokens\n",
      "Embedded text shape: torch.Size([5, 128])\n",
      "Embedding array with custom formatting:\n",
      "[[ 0.1381  0.5469 -1.076  ... -0.3798 -0.7187  0.2953]\n",
      " [ 0.1925 -0.0985 -0.1367 ...  0.7328  0.5067  0.7939]\n",
      " [ 0.2072  0.043  -0.6497 ... -0.0641 -0.6588 -0.1389]\n",
      " [ 0.418  -0.645  -0.5003 ... -0.159  -0.2203 -0.2697]\n",
      " [-0.4971  0.4175 -0.0469 ... -0.1927  2.253  -0.1716]]\n"
     ]
    }
   ],
   "source": [
    "# Paths to your files\n",
    "embeddings_path = \"./downloaded_model/embeddings.pt\"\n",
    "vocab_path = \"./downloaded_model/tkn_ids_to_words.csv\"\n",
    "\n",
    "# Load embeddings and vocabulary\n",
    "print(\"Loading embeddings and vocabulary...\")\n",
    "embeddings = load_embeddings(embeddings_path)\n",
    "word_to_idx = load_vocabulary(vocab_path)\n",
    "\n",
    "print(f\"Loaded embeddings with shape: {embeddings.shape}\")\n",
    "print(f\"Loaded vocabulary with {len(word_to_idx)} tokens\")\n",
    "\n",
    "# Example usage (uncomment when ready to test)\n",
    "sample_text = \"This is a test sentence\"\n",
    "embeddings_result = text_to_embeddings(sample_text, word_to_idx, embeddings)\n",
    "print(f\"Embedded text shape: {embeddings_result.shape}\")\n",
    "\n",
    "# Testing - Set numpy print options\n",
    "np.set_printoptions(precision=4, suppress=True, threshold=10)  # threshold limits number of elements shown\n",
    "numpy_array = embeddings_result.detach().numpy()\n",
    "print(\"Embedding array with custom formatting:\")\n",
    "print(numpy_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55fa305b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['query_id', 'query', 'positive_passage', 'negative_passage', 'negative_from_query_id'],\n",
       "        num_rows: 79704\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_soft_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53a28244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soft_neg  = pd.DataFrame(ds_soft_neg['train'])\n",
    "df_hard_neg  = pd.DataFrame(ds_hard_neg['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b81dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_query = text_to_embeddings(df_soft_neg['query'][0], word_to_idx, embeddings)\n",
    "embedded_positive = text_to_embeddings(df_soft_neg['positive_passage'][0], word_to_idx, embeddings)\n",
    "embedded_negative = text_to_embeddings(df_soft_neg['negative_passage'][0], word_to_idx, embeddings)\n",
    "\n",
    "embedded_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ece943f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = embedded_query.mean(dim=0)\n",
    "b = embedded_positive.mean(dim=0)\n",
    "c = embedded_negative.mean(dim=0)\n",
    "a.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e95b8699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between query and positive passage: 0.7518182992935181\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "cosine_similarity = F.cosine_similarity(a, c, dim=0)\n",
    "print(f\"Cosine similarity between query and positive passage: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b6a0d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating similarities... This may take a while depending on dataframe size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 554.16it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Process the dataframe using apply just for first five rows\n",
    "print(\"Calculating similarities... This may take a while depending on dataframe size.\")\n",
    "similarities = df_soft_neg[0:5].progress_apply(\n",
    "    lambda row: calculate_similarities(row, word_to_idx, embeddings), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Join the similarities to the dataframe\n",
    "df_soft_neg_ext = pd.concat([df_soft_neg[0:5], similarities], axis=1)\n",
    "\n",
    "# Show a sample of the results\n",
    "#print(df_soft_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c48c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   query_id                                              query  \\\n",
      "0     19699                                        what is rba   \n",
      "1     19700                       was ronald reagan a democrat   \n",
      "2     19701  how long do you need for sydney and surroundin...   \n",
      "3     19702                    price to install tile in shower   \n",
      "4     19703                    why conversion observed in body   \n",
      "\n",
      "                                    positive_passage  \\\n",
      "0  Results-Based Accountability® (also known as R...   \n",
      "1  From Wikipedia, the free encyclopedia. A Reaga...   \n",
      "2  Sydney is the capital city of the Australian s...   \n",
      "3  1 Install ceramic tile floor to match shower-A...   \n",
      "4  Conversion disorder is a type of somatoform di...   \n",
      "\n",
      "                                    negative_passage  negative_from_query_id  \\\n",
      "0  I finally found some real salary data for phys...                   86595   \n",
      "1  The Pacific Ocean lies to the east while the S...                   66360   \n",
      "2  Probiotics are found in foods such as yogurt, ...                   88507   \n",
      "3  Iodine is critical to thyroid health and funct...                   87550   \n",
      "4  The answer to the question how much does it co...                   61479   \n",
      "\n",
      "                                 avg_query_embedding  \\\n",
      "0  [0.6579812, 0.24213153, 0.057250064, -0.825741...   \n",
      "1  [-0.6998242, -0.24631366, -0.20571017, 0.24202...   \n",
      "2  [0.16817716, 0.29739928, -0.36492547, 0.064426...   \n",
      "3  [-0.06541735, 0.2755244, 0.19580394, 0.4023429...   \n",
      "4  [-0.13369766, -0.30740747, 0.5450557, 0.391294...   \n",
      "\n",
      "                                   avg_pos_embedding  \\\n",
      "0  [0.39086032, 0.3319433, 0.1275278, -0.80645, 0...   \n",
      "1  [0.27046937, 0.2619914, 0.049588773, -0.618945...   \n",
      "2  [0.39110944, 0.23566554, 0.063871, -0.36585316...   \n",
      "3  [0.69151133, 0.5770993, 0.22074986, -0.7754023...   \n",
      "4  [0.42539537, 0.13814452, 0.37000972, -0.632320...   \n",
      "\n",
      "                                   avg_neg_embedding  \n",
      "0  [0.569893, 0.18935415, 0.1920344, -0.7171183, ...  \n",
      "1  [0.17404862, 0.21760696, -0.10469024, -0.23737...  \n",
      "2  [0.61134595, 0.36615297, 0.28972, -0.6924668, ...  \n",
      "3  [0.3590759, -0.036869664, 0.17250647, -0.53339...  \n",
      "4  [0.5729694, 0.314426, 0.13929352, -0.9086552, ...  \n",
      "Index(['query_id', 'query', 'positive_passage', 'negative_passage',\n",
      "       'negative_from_query_id', 'avg_query_embedding', 'avg_pos_embedding',\n",
      "       'avg_neg_embedding'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_soft_neg_ext.head())\n",
    "print(df_soft_neg_ext.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a02f39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating similarities... This may take a while depending on dataframe size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79704/79704 [02:29<00:00, 534.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   query_id                                              query  \\\n",
      "0     19699                                        what is rba   \n",
      "1     19700                       was ronald reagan a democrat   \n",
      "2     19701  how long do you need for sydney and surroundin...   \n",
      "3     19702                    price to install tile in shower   \n",
      "4     19703                    why conversion observed in body   \n",
      "\n",
      "                                    positive_passage  \\\n",
      "0  Results-Based Accountability® (also known as R...   \n",
      "1  From Wikipedia, the free encyclopedia. A Reaga...   \n",
      "2  Sydney is the capital city of the Australian s...   \n",
      "3  1 Install ceramic tile floor to match shower-A...   \n",
      "4  Conversion disorder is a type of somatoform di...   \n",
      "\n",
      "                                    negative_passage  negative_from_query_id  \\\n",
      "0  I finally found some real salary data for phys...                   86595   \n",
      "1  The Pacific Ocean lies to the east while the S...                   66360   \n",
      "2  Probiotics are found in foods such as yogurt, ...                   88507   \n",
      "3  Iodine is critical to thyroid health and funct...                   87550   \n",
      "4  The answer to the question how much does it co...                   61479   \n",
      "\n",
      "                                 avg_query_embedding  \\\n",
      "0  [0.6579812, 0.24213153, 0.057250064, -0.825741...   \n",
      "1  [-0.6998242, -0.24631366, -0.20571017, 0.24202...   \n",
      "2  [0.16817716, 0.29739928, -0.36492547, 0.064426...   \n",
      "3  [-0.06541735, 0.2755244, 0.19580394, 0.4023429...   \n",
      "4  [-0.13369766, -0.30740747, 0.5450557, 0.391294...   \n",
      "\n",
      "                                   avg_pos_embedding  \\\n",
      "0  [0.39086032, 0.3319433, 0.1275278, -0.80645, 0...   \n",
      "1  [0.27046937, 0.2619914, 0.049588773, -0.618945...   \n",
      "2  [0.39110944, 0.23566554, 0.063871, -0.36585316...   \n",
      "3  [0.69151133, 0.5770993, 0.22074986, -0.7754023...   \n",
      "4  [0.42539537, 0.13814452, 0.37000972, -0.632320...   \n",
      "\n",
      "                                   avg_neg_embedding  \n",
      "0  [0.569893, 0.18935415, 0.1920344, -0.7171183, ...  \n",
      "1  [0.17404862, 0.21760696, -0.10469024, -0.23737...  \n",
      "2  [0.61134595, 0.36615297, 0.28972, -0.6924668, ...  \n",
      "3  [0.3590759, -0.036869664, 0.17250647, -0.53339...  \n",
      "4  [0.5729694, 0.314426, 0.13929352, -0.9086552, ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Process the dataframe using apply\n",
    "print(\"Calculating similarities... This may take a while depending on dataframe size.\")\n",
    "similarities = df_soft_neg.progress_apply(\n",
    "    lambda row: calculate_similarities(row, word_to_idx, embeddings), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Join the similarities to the dataframe\n",
    "df_soft_neg_ext = pd.concat([df_soft_neg, similarities], axis=1)\n",
    "print(df_soft_neg_ext.head())\n",
    "# Show a sample of the results\n",
    "#print(df_soft_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].head())\n",
    "\n",
    "#print(df_soft_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].mean())\n",
    "\n",
    "# Calculate how often the positive passage is ranked higher than negative\n",
    "#higher_count = (df_soft_neg_ext['query_pos_sim'] > df_soft_neg_ext['query_neg_sim']).sum()\n",
    "#total = len(df_soft_neg_ext)\n",
    "#print(f\"\\nPositive passage ranked higher than negative: {higher_count} out of {total} ({higher_count/total:.2%})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fbbd3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating similarities... This may take a while depending on dataframe size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79700/79700 [02:35<00:00, 513.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   query_id                                              query  \\\n",
      "0     19699                                        what is rba   \n",
      "1     19700                       was ronald reagan a democrat   \n",
      "2     19701  how long do you need for sydney and surroundin...   \n",
      "3     19702                    price to install tile in shower   \n",
      "4     19703                    why conversion observed in body   \n",
      "\n",
      "                                    positive_passage  \\\n",
      "0  Results-Based Accountability® (also known as R...   \n",
      "1  From Wikipedia, the free encyclopedia. A Reaga...   \n",
      "2  Sydney is the capital city of the Australian s...   \n",
      "3  1 Install ceramic tile floor to match shower-A...   \n",
      "4  Conversion disorder is a type of somatoform di...   \n",
      "\n",
      "                                    negative_passage  negative_index_in_group  \\\n",
      "0  vs. NetIQ Identity Manager. Risk-based authent...                        8   \n",
      "1  1984 Re-Election. In November 1984, Ronald Rea...                        7   \n",
      "2  The Sydney central business district, Sydney h...                        3   \n",
      "3  The national average for a new shower installa...                        8   \n",
      "4  Conclusions: In adult body CT, dose to an orga...                        1   \n",
      "\n",
      "                                 avg_query_embedding  \\\n",
      "0  [0.6579812, 0.24213153, 0.057250064, -0.825741...   \n",
      "1  [-0.6998242, -0.24631366, -0.20571017, 0.24202...   \n",
      "2  [0.16817716, 0.29739928, -0.36492547, 0.064426...   \n",
      "3  [-0.06541735, 0.2755244, 0.19580394, 0.4023429...   \n",
      "4  [-0.13369766, -0.30740747, 0.5450557, 0.391294...   \n",
      "\n",
      "                                   avg_pos_embedding  \\\n",
      "0  [0.39086032, 0.3319433, 0.1275278, -0.80645, 0...   \n",
      "1  [0.27046937, 0.2619914, 0.049588773, -0.618945...   \n",
      "2  [0.39110944, 0.23566554, 0.063871, -0.36585316...   \n",
      "3  [0.69151133, 0.5770993, 0.22074986, -0.7754023...   \n",
      "4  [0.42539537, 0.13814452, 0.37000972, -0.632320...   \n",
      "\n",
      "                                   avg_neg_embedding  \n",
      "0  [0.5515162, 0.2642954, 0.1885793, -0.75945073,...  \n",
      "1  [0.44075873, 0.46540666, 0.2389529, -0.8843408...  \n",
      "2  [0.6332741, 0.20384072, 0.1361951, -0.66839683...  \n",
      "3  [0.87775123, 0.5726479, 0.21296756, -0.7518157...  \n",
      "4  [0.45698056, 0.28827518, 0.243968, -0.54975086...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process the dataframe using apply\n",
    "print(\"Calculating similarities... This may take a while depending on dataframe size.\")\n",
    "similarities = df_hard_neg.progress_apply(\n",
    "    lambda row: calculate_similarities(row, word_to_idx, embeddings), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Join the similarities to the dataframe\n",
    "df_hard_neg_ext = pd.concat([df_hard_neg, similarities], axis=1)\n",
    "print(df_hard_neg_ext.head())\n",
    "# Show a sample of the results\n",
    "#print(df_hard_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].head())\n",
    "\n",
    "#print(df_hard_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].mean())\n",
    "\n",
    "# Calculate how often the positive passage is ranked higher than negative\n",
    "#higher_count = (df_hard_neg_ext['query_pos_sim'] > df_hard_neg_ext['query_neg_sim']).sum()\n",
    "#total = len(df_hard_neg_ext)\n",
    "#print(f\"\\nPositive passage ranked higher than negative: {higher_count} out of {total} ({higher_count/total:.2%})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba3edcd",
   "metadata": {},
   "source": [
    "### Twin Tower Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239cc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tower instances\n",
    "qryTower = QryTower()\n",
    "docTower = DocTower()\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 128\n",
    "num_epochs = 1 # adjust num of epochs here\n",
    "dataset_size = len(df_soft_neg_ext)  # or len(df_hard_neg_ext) depending on the dataset you want to use\n",
    "steps_per_epoch = dataset_size // batch_size\n",
    "total_steps = steps_per_epoch * num_epochs\n",
    "learning_rate = 1e-3\n",
    "embedding_dim = 128 \n",
    "margin = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = TripletEmbeddingDataset(df_soft_neg_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7753f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    #num_workers=2,  # Adjust based on your machine's capabilities\n",
    "    pin_memory=True  # Set to True if using GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = torch.randn(batch_size, embedding_dim)  # Query embeddings\n",
    "pos = torch.randn(batch_size, embedding_dim)  # Positive doc embeddings\n",
    "neg = torch.randn(batch_size, embedding_dim)  # Negative doc embeddings\n",
    "\n",
    "#qry = df1['q']\n",
    "\n",
    "\n",
    "# Set up the AdamW optimizer\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': qryTower.parameters()},\n",
    "    {'params': docTower.parameters()}\n",
    "], lr=learning_rate)\n",
    "\n",
    "# Add learning rate scheduler (ReduceLROnPlateau)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',       # Reduce LR when monitored value stops decreasing\n",
    "    factor=0.5,       # Multiply LR by this factor when reducing\n",
    "    patience=2,       # Number of epochs with no improvement after which LR will be reduced\n",
    "    verbose=True      # Print message when LR is reduced\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aedf0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (simplified example)\n",
    "for epoch in range(num_epochs):\n",
    "    qryTower.train()\n",
    "    docTower.train()\n",
    "    \n",
    "    \n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        # Get embeddings from batch\n",
    "        query_emb = batch['query']\n",
    "        pos_emb = batch['positive']\n",
    "        neg_emb = batch['negative']\n",
    "        \n",
    "        # Forward pass through towers\n",
    "        query_encoded = qryTower(query_emb)\n",
    "        pos_encoded = docTower(pos_emb)\n",
    "        neg_encoded = docTower(neg_emb)\n",
    "        \n",
    "        # Calculate similarities\n",
    "        pos_sim = torch.nn.functional.cosine_similarity(query_encoded, pos_encoded)\n",
    "        neg_sim = torch.nn.functional.cosine_similarity(query_encoded, neg_encoded)\n",
    "        \n",
    "        # Triplet loss\n",
    "        margin = margin\n",
    "        loss = torch.clamp(margin - pos_sim + neg_sim, min=0).mean()\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * len(query_emb)\n",
    "    \n",
    "    # Calculate average loss\n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, \"\n",
    "          f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9beb07bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training with output_dim=128, batch_size=256\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Train):   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Train): 100%|██████████| 200/200 [00:10<00:00, 19.67it/s]\n",
      "Epoch 1/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 19.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.0486, Val Loss: 0.0065, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Train): 100%|██████████| 200/200 [00:09<00:00, 20.57it/s]\n",
      "Epoch 2/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 21.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.0222, Val Loss: 0.0061, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Train): 100%|██████████| 200/200 [00:10<00:00, 19.60it/s]\n",
      "Epoch 3/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 19.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.0178, Val Loss: 0.0056, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Train): 100%|██████████| 200/200 [00:09<00:00, 20.93it/s]\n",
      "Epoch 4/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 20.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.0151, Val Loss: 0.0052, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Train): 100%|██████████| 200/200 [00:09<00:00, 20.79it/s]\n",
      "Epoch 5/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 20.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.0134, Val Loss: 0.0050, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0050\n",
      "\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Train): 100%|██████████| 200/200 [00:09<00:00, 20.36it/s]\n",
      "Epoch 1/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 21.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.0494, Val Loss: 0.0070, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Train): 100%|██████████| 200/200 [00:09<00:00, 21.65it/s]\n",
      "Epoch 2/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 20.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.0229, Val Loss: 0.0064, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Train): 100%|██████████| 200/200 [00:10<00:00, 19.12it/s]\n",
      "Epoch 3/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 20.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.0188, Val Loss: 0.0057, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Train): 100%|██████████| 200/200 [00:09<00:00, 20.64it/s]\n",
      "Epoch 4/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 20.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.0162, Val Loss: 0.0051, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Train): 100%|██████████| 200/200 [00:09<00:00, 20.63it/s]\n",
      "Epoch 5/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 22.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.0140, Val Loss: 0.0050, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0050\n",
      "\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Train): 100%|██████████| 200/200 [00:09<00:00, 20.25it/s]\n",
      "Epoch 1/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 21.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.0485, Val Loss: 0.0063, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Train): 100%|██████████| 200/200 [00:10<00:00, 19.92it/s]\n",
      "Epoch 2/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.0222, Val Loss: 0.0055, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Train): 100%|██████████| 200/200 [00:09<00:00, 20.08it/s]\n",
      "Epoch 3/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 20.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.0178, Val Loss: 0.0053, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Train): 100%|██████████| 200/200 [00:10<00:00, 19.26it/s]\n",
      "Epoch 4/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 22.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.0151, Val Loss: 0.0051, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Train): 100%|██████████| 200/200 [00:10<00:00, 19.41it/s]\n",
      "Epoch 5/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 21.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.0132, Val Loss: 0.0049, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0049\n",
      "\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Train): 100%|██████████| 200/200 [00:09<00:00, 20.27it/s]\n",
      "Epoch 1/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 22.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.0491, Val Loss: 0.0065, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Train): 100%|██████████| 200/200 [00:09<00:00, 20.22it/s]\n",
      "Epoch 2/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 21.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.0226, Val Loss: 0.0058, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Train): 100%|██████████| 200/200 [00:10<00:00, 19.20it/s]\n",
      "Epoch 3/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 21.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.0180, Val Loss: 0.0054, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Train): 100%|██████████| 200/200 [00:09<00:00, 20.99it/s]\n",
      "Epoch 4/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 22.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.0154, Val Loss: 0.0051, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Train): 100%|██████████| 200/200 [00:09<00:00, 20.11it/s]\n",
      "Epoch 5/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 19.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.0134, Val Loss: 0.0045, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0045\n",
      "\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Train): 100%|██████████| 200/200 [00:09<00:00, 20.03it/s]\n",
      "Epoch 1/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 20.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.0495, Val Loss: 0.0066, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Train): 100%|██████████| 200/200 [00:10<00:00, 19.54it/s]\n",
      "Epoch 2/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.0236, Val Loss: 0.0057, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Train): 100%|██████████| 200/200 [00:11<00:00, 17.77it/s]\n",
      "Epoch 3/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 22.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.0180, Val Loss: 0.0051, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Train): 100%|██████████| 200/200 [00:11<00:00, 17.29it/s]\n",
      "Epoch 4/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 20.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.0155, Val Loss: 0.0050, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Train): 100%|██████████| 200/200 [00:10<00:00, 18.89it/s]\n",
      "Epoch 5/5 (Val): 100%|██████████| 50/50 [00:02<00:00, 22.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.0136, Val Loss: 0.0046, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0046\n",
      "\n",
      "Average CV loss for output_dim=128, batch_size=256: 0.0048\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training with output_dim=128, batch_size=512\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Train): 100%|██████████| 100/100 [00:07<00:00, 12.62it/s]\n",
      "Epoch 1/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 15.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.0600, Val Loss: 0.0070, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Train): 100%|██████████| 100/100 [00:06<00:00, 14.60it/s]\n",
      "Epoch 2/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.0239, Val Loss: 0.0059, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Train): 100%|██████████| 100/100 [00:07<00:00, 13.71it/s]\n",
      "Epoch 3/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.0190, Val Loss: 0.0053, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Train): 100%|██████████| 100/100 [00:06<00:00, 14.73it/s]\n",
      "Epoch 4/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 16.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.0159, Val Loss: 0.0051, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Train): 100%|██████████| 100/100 [00:07<00:00, 13.32it/s]\n",
      "Epoch 5/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.0142, Val Loss: 0.0051, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0051\n",
      "\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Train): 100%|██████████| 100/100 [00:07<00:00, 13.56it/s]\n",
      "Epoch 1/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 14.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.0616, Val Loss: 0.0071, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Train): 100%|██████████| 100/100 [00:06<00:00, 14.86it/s]\n",
      "Epoch 2/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 15.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.0243, Val Loss: 0.0058, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Train): 100%|██████████| 100/100 [00:07<00:00, 12.66it/s]\n",
      "Epoch 3/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 16.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.0187, Val Loss: 0.0051, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Train): 100%|██████████| 100/100 [00:07<00:00, 13.23it/s]\n",
      "Epoch 4/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.0161, Val Loss: 0.0050, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Train): 100%|██████████| 100/100 [00:07<00:00, 13.19it/s]\n",
      "Epoch 5/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.0140, Val Loss: 0.0048, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0048\n",
      "\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Train): 100%|██████████| 100/100 [00:07<00:00, 14.16it/s]\n",
      "Epoch 1/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.0605, Val Loss: 0.0074, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Train): 100%|██████████| 100/100 [00:08<00:00, 12.38it/s]\n",
      "Epoch 2/5 (Val): 100%|██████████| 25/25 [00:02<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.0244, Val Loss: 0.0058, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Train): 100%|██████████| 100/100 [00:07<00:00, 13.76it/s]\n",
      "Epoch 3/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.0187, Val Loss: 0.0054, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Train): 100%|██████████| 100/100 [00:07<00:00, 13.74it/s]\n",
      "Epoch 4/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.0160, Val Loss: 0.0050, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Train): 100%|██████████| 100/100 [00:06<00:00, 14.59it/s]\n",
      "Epoch 5/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.0139, Val Loss: 0.0052, LR: 0.001000\n",
      "\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Train): 100%|██████████| 100/100 [00:07<00:00, 14.06it/s]\n",
      "Epoch 1/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 15.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.0636, Val Loss: 0.0076, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Train): 100%|██████████| 100/100 [00:08<00:00, 12.46it/s]\n",
      "Epoch 2/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 16.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.0251, Val Loss: 0.0058, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Train): 100%|██████████| 100/100 [00:06<00:00, 14.41it/s]\n",
      "Epoch 3/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.0189, Val Loss: 0.0053, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Train): 100%|██████████| 100/100 [00:06<00:00, 14.71it/s]\n",
      "Epoch 4/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 15.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.0158, Val Loss: 0.0050, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Train): 100%|██████████| 100/100 [00:06<00:00, 14.39it/s]\n",
      "Epoch 5/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.0139, Val Loss: 0.0052, LR: 0.001000\n",
      "\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Train): 100%|██████████| 100/100 [00:06<00:00, 14.97it/s]\n",
      "Epoch 1/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 16.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.0609, Val Loss: 0.0077, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Train): 100%|██████████| 100/100 [00:07<00:00, 13.22it/s]\n",
      "Epoch 2/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 15.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.0243, Val Loss: 0.0056, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Train): 100%|██████████| 100/100 [00:07<00:00, 12.56it/s]\n",
      "Epoch 3/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 16.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.0191, Val Loss: 0.0053, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Train): 100%|██████████| 100/100 [00:06<00:00, 14.38it/s]\n",
      "Epoch 4/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.0160, Val Loss: 0.0049, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Train): 100%|██████████| 100/100 [00:07<00:00, 13.58it/s]\n",
      "Epoch 5/5 (Val): 100%|██████████| 25/25 [00:01<00:00, 15.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.0137, Val Loss: 0.0050, LR: 0.001000\n",
      "\n",
      "Average CV loss for output_dim=128, batch_size=512: 0.0050\n",
      "\n",
      "\n",
      "Best hyperparameters:\n",
      "Output dimension: 128\n",
      "Batch size: 256\n",
      "Average CV loss: 0.0048\n",
      "\n",
      "\n",
      "Training final model with best hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Train): 100%|██████████| 250/250 [00:13<00:00, 18.83it/s]\n",
      "Epoch 1/5 (Val): 100%|██████████| 63/63 [00:02<00:00, 21.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.0535, Val Loss: 0.0325, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Train): 100%|██████████| 250/250 [00:13<00:00, 18.35it/s]\n",
      "Epoch 2/5 (Val): 100%|██████████| 63/63 [00:02<00:00, 21.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.0262, Val Loss: 0.0286, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Train): 100%|██████████| 250/250 [00:15<00:00, 16.39it/s]\n",
      "Epoch 3/5 (Val): 100%|██████████| 63/63 [00:02<00:00, 24.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.0216, Val Loss: 0.0267, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Train): 100%|██████████| 250/250 [00:13<00:00, 18.09it/s]\n",
      "Epoch 4/5 (Val): 100%|██████████| 63/63 [00:02<00:00, 22.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.0184, Val Loss: 0.0268, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Train): 100%|██████████| 250/250 [00:13<00:00, 18.94it/s]\n",
      "Epoch 5/5 (Val): 100%|██████████| 63/63 [00:02<00:00, 25.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.0167, Val Loss: 0.0261, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0261\n",
      "Best output dimension: 128\n",
      "Best batch size: 256\n",
      "Best validation loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the hyperparameter tuning with your dataframe\n",
    "best_params, final_qry_tower, final_doc_tower = run_hyperparameter_tuning(\n",
    "    df_soft_neg_ext,\n",
    "    output_dims=[128],\n",
    "    batch_sizes=[256, 512],\n",
    "    n_folds=5,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Print the best parameters found\n",
    "print(f\"Best output dimension: {best_params['output_dim']}\")\n",
    "print(f\"Best batch size: {best_params['batch_size']}\")\n",
    "print(f\"Best validation loss: {best_params['avg_cv_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11581eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to Weights & Biases\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/MLX_Week2/wandb/run-20250422_174711-nsn6t8fa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/twin-tower-model/runs/nsn6t8fa' target=\"_blank\">final-model</a></strong> to <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/twin-tower-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/twin-tower-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/twin-tower-model/runs/nsn6t8fa' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/twin-tower-model/runs/nsn6t8fa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">final-model</strong> at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/twin-tower-model/runs/nsn6t8fa' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/twin-tower-model/runs/nsn6t8fa</a><br> View project at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/twin-tower-model</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250422_174711-nsn6t8fa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model uploaded to Weights & Biases project: twin-tower-model\n"
     ]
    }
   ],
   "source": [
    "# Code to upload final model to wandb\n",
    "import wandb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load your API key from config.txt\n",
    "def load_api_key_from_config(config_path=\"config.txt\"):\n",
    "    try:\n",
    "        with open(config_path, \"r\") as f:\n",
    "            first_line = f.readline().strip()\n",
    "            if \"=\" in first_line:\n",
    "                api_key = first_line.split(\"=\")[1].strip()\n",
    "            else:\n",
    "                api_key = first_line\n",
    "        return api_key\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Config file not found at {config_path}\")\n",
    "        return None\n",
    "\n",
    "# Set up wandb\n",
    "api_key = load_api_key_from_config()\n",
    "if api_key:\n",
    "    os.environ[\"WANDB_API_KEY\"] = api_key\n",
    "    wandb.login()\n",
    "    print(\"Successfully logged in to Weights & Biases\")\n",
    "else:\n",
    "    print(\"Failed to load API key\")\n",
    "    \n",
    "# Initialize a new wandb run\n",
    "run = wandb.init(\n",
    "    project=\"twin-tower-model\",\n",
    "    name=\"final-model\",\n",
    "    config={\n",
    "        \"output_dim\": best_params[\"output_dim\"],\n",
    "        \"batch_size\": best_params[\"batch_size\"],\n",
    "        \"architecture\": \"Twin Tower Network\",\n",
    "        \"dataset\": \"MS MARCO\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Upload the final model\n",
    "final_model_path = \"checkpoints/final_model/final_model.pt\"\n",
    "model_artifact = wandb.Artifact(\n",
    "    name=\"twin-tower-final-model\", \n",
    "    type=\"model\",\n",
    "    description=\"Twin Tower model trained on full training data with optimal hyperparameters\"\n",
    ")\n",
    "model_artifact.add_file(final_model_path)\n",
    "wandb.log_artifact(model_artifact)\n",
    "\n",
    "wandb.finish()\n",
    "print(f\"Final model uploaded to Weights & Biases project: {run.project}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

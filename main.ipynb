{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b0ec85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nnamd\\OneDrive\\Python_learning\\MLX\\MLX_Week2\\mlx_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnnamdi-odozi\u001b[0m (\u001b[33mnnamdi-odozi-ave-actuaries\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from load_models_and_data import load_vocabulary, load_embeddings, text_to_embeddings, calc_cosine_sim, calculate_embeddings, create_packed_batch\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "#from TwoTowerNN import QryTower, DocTower, TripletEmbeddingDataset, run_hyperparameter_tuning\n",
    "from TwinTowerGRU import QryTower, DocTower, EmbeddingTripletDataset, run_hyperparameter_tuning\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader,  SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import os\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b860fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba466e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Loading datasets from Hugging Face\n",
    "ds_soft_neg = load_dataset(\"cocoritzy/week_2_triplet_dataset_soft_negatives\")\n",
    "ds_hard_neg = load_dataset(\"cocoritzy/week_2_triplet_dataset_hard_negatives\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a1948ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings and vocabulary...\n",
      "Loaded embeddings with shape: torch.Size([400000, 100])\n",
      "Loaded vocabulary with 399998 tokens\n",
      "Embedded text shape: torch.Size([26, 100])\n",
      "Embedding array with custom formatting:\n",
      "[[ 0.2616  0.4472 -0.0968 ... -0.4503  0.4952 -0.203 ]\n",
      " [ 0.1372 -0.5429  0.1942 ... -0.5206  0.2543 -0.2376]\n",
      " [-0.3046 -0.2365  0.1758 ... -0.8456 -0.0354  0.1704]\n",
      " ...\n",
      " [ 0.      0.      0.     ...  0.      0.      0.    ]\n",
      " [ 0.      0.      0.     ...  0.      0.      0.    ]\n",
      " [ 0.      0.      0.     ...  0.      0.      0.    ]]\n",
      "Length is: 5\n"
     ]
    }
   ],
   "source": [
    "# Paths to your files\n",
    "embeddings_path = \"./downloaded_model/glove_embeddings.pt\" #set this to either own-trained cbow ones or to glove pre-trained ones\n",
    "vocab_path = \"./downloaded_model/glove_ids_to_words.csv\"\n",
    "\n",
    "# Load embeddings and vocabulary\n",
    "print(\"Loading embeddings and vocabulary...\")\n",
    "embeddings = load_embeddings(embeddings_path)\n",
    "word_to_idx = load_vocabulary(vocab_path)\n",
    "\n",
    "print(f\"Loaded embeddings with shape: {embeddings.shape}\")\n",
    "print(f\"Loaded vocabulary with {len(word_to_idx)} tokens\")\n",
    "\n",
    "# Example usage (uncomment when ready to test)\n",
    "sample_text = \"This is a test sentence\"\n",
    "embeddings_result, length = text_to_embeddings(sample_text, word_to_idx, embeddings, is_query=True)\n",
    "print(f\"Embedded text shape: {embeddings_result.shape}\")\n",
    "\n",
    "# Testing - Set numpy print options\n",
    "np.set_printoptions(precision=4, suppress=True, threshold=10)  # threshold limits number of elements shown\n",
    "numpy_array = embeddings_result.detach().numpy()\n",
    "print(\"Embedding array with custom formatting:\")\n",
    "print(numpy_array)\n",
    "print(\"Length is:\", length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff426027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded text shape: torch.Size([26, 100])\n",
      "Embedding array with custom formatting:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Length is: 0\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\n",
    "embeddings_result, length = text_to_embeddings(sample_text, word_to_idx, embeddings, is_query=True)\n",
    "print(f\"Embedded text shape: {embeddings_result.shape}\")\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True, threshold=10)  # threshold limits number of elements shown\n",
    "numpy_array = embeddings_result.detach().numpy()\n",
    "print(\"Embedding array with custom formatting:\")\n",
    "print(numpy_array)\n",
    "print(\"Length is:\", length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53a28244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soft_neg  = pd.DataFrame(ds_soft_neg['train'])\n",
    "df_hard_neg  = pd.DataFrame(ds_hard_neg['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7b81dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([201, 100])\n",
      "torch.Size([201, 100])\n"
     ]
    }
   ],
   "source": [
    "embedded_query, length = text_to_embeddings(df_soft_neg['query'][0], word_to_idx, embeddings, is_query=True)\n",
    "embedded_positive, length = text_to_embeddings(df_soft_neg['positive_passage'][0], word_to_idx, embeddings, is_query=False)\n",
    "embedded_negative, length = text_to_embeddings(df_soft_neg['negative_passage'][0], word_to_idx, embeddings, is_query=False)\n",
    "\n",
    "print(embedded_positive.shape)\n",
    "print(embedded_negative.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ece943f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = embedded_query.mean(dim=0)\n",
    "b = embedded_positive.mean(dim=0)\n",
    "c = embedded_negative.mean(dim=0)\n",
    "a.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "cosine_similarity = F.cosine_similarity(a, c, dim=0)\n",
    "print(f\"Cosine similarity between query and positive passage: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Process the dataframe using apply just for first five rows\n",
    "# print(\"Calculating similarities... This may take a while depending on dataframe size.\")\n",
    "# similarities = df_soft_neg[0:5].progress_apply(\n",
    "#     lambda row: calculate_similarities(row, word_to_idx, embeddings), \n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # Join the similarities to the dataframe\n",
    "# df_soft_neg_ext = pd.concat([df_soft_neg[0:5], similarities], axis=1)\n",
    "\n",
    "# # Show a sample of the results\n",
    "# #print(df_soft_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].head())\n",
    "#print(df_soft_neg_ext.head())\n",
    "#print(df_soft_neg_ext.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a02f39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating embeddings... This may take a while depending on dataframe size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79704/79704 [04:56<00:00, 269.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   query_id                                              query  \\\n",
      "0     19699                                        what is rba   \n",
      "1     19700                       was ronald reagan a democrat   \n",
      "2     19701  how long do you need for sydney and surroundin...   \n",
      "3     19702                    price to install tile in shower   \n",
      "4     19703                    why conversion observed in body   \n",
      "\n",
      "                                    positive_passage  \\\n",
      "0  Results-Based Accountability® (also known as R...   \n",
      "1  From Wikipedia, the free encyclopedia. A Reaga...   \n",
      "2  Sydney is the capital city of the Australian s...   \n",
      "3  1 Install ceramic tile floor to match shower-A...   \n",
      "4  Conversion disorder is a type of somatoform di...   \n",
      "\n",
      "                                    negative_passage  negative_from_query_id  \\\n",
      "0  I finally found some real salary data for phys...                   86595   \n",
      "1  The Pacific Ocean lies to the east while the S...                   66360   \n",
      "2  Probiotics are found in foods such as yogurt, ...                   88507   \n",
      "3  Iodine is critical to thyroid health and funct...                   87550   \n",
      "4  The answer to the question how much does it co...                   61479   \n",
      "\n",
      "                                           query_emb  query_length  \\\n",
      "0  [[tensor(0.0424), tensor(-0.5220), tensor(0.40...             3   \n",
      "1  [[tensor(-0.1313), tensor(-0.4520), tensor(0.0...             5   \n",
      "2  [[tensor(0.2753), tensor(0.2256), tensor(-0.29...            10   \n",
      "3  [[tensor(0.4291), tensor(-0.1227), tensor(0.05...             6   \n",
      "4  [[tensor(0.1736), tensor(0.3796), tensor(0.132...             5   \n",
      "\n",
      "                                             pos_emb  pos_length  \\\n",
      "0  [[tensor(0.0448), tensor(0.0507), tensor(0.194...         110   \n",
      "1  [[tensor(0.1288), tensor(-0.8221), tensor(0.27...         104   \n",
      "2  [[tensor(0.1867), tensor(-0.7999), tensor(0.79...         101   \n",
      "3  [[tensor(0.0911), tensor(-0.3988), tensor(0.30...          53   \n",
      "4  [[tensor(-0.0087), tensor(0.0675), tensor(-0.1...          49   \n",
      "\n",
      "                                             neg_emb  neg_length  \n",
      "0  [[tensor(0.0302), tensor(0.4461), tensor(0.431...          67  \n",
      "1  [[tensor(-0.1077), tensor(0.1105), tensor(0.59...          95  \n",
      "2  [[tensor(-0.3277), tensor(-0.4549), tensor(-0....          98  \n",
      "3  [[tensor(-0.2682), tensor(-0.0228), tensor(0.2...          49  \n",
      "4  [[tensor(-0.1077), tensor(0.1105), tensor(0.59...          46  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Process the dataframe using apply\n",
    "print(\"Calculating embeddings... This may take a while depending on dataframe size.\")\n",
    "embeddings_padded = df_soft_neg.progress_apply(\n",
    "    lambda row: calculate_embeddings(row, word_to_idx, embeddings), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Join the similarities to the dataframe\n",
    "df_soft_neg_ext = pd.concat([df_soft_neg, embeddings_padded], axis=1)\n",
    "print(df_soft_neg_ext.head())\n",
    "# Show a sample of the results\n",
    "#print(df_soft_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].head())\n",
    "\n",
    "#print(df_soft_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].mean())\n",
    "\n",
    "# Calculate how often the positive passage is ranked higher than negative\n",
    "#higher_count = (df_soft_neg_ext['query_pos_sim'] > df_soft_neg_ext['query_neg_sim']).sum()\n",
    "#total = len(df_soft_neg_ext)\n",
    "#print(f\"\\nPositive passage ranked higher than negative: {higher_count} out of {total} ({higher_count/total:.2%})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1926f19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "query_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "query",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "positive_passage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "negative_passage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "negative_from_query_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "query_emb",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "query_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pos_emb",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "pos_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "neg_emb",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "neg_length",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "995d2277-3ca0-42f6-8171-6eb130c6d9c7",
       "rows": [
        [
         "0",
         "19699",
         "what is rba",
         "Results-Based Accountability® (also known as RBA) is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole. RBA is also used by organizations to improve the performance of their programs. Creating Community Impact with RBA. Community impact focuses on conditions of well-being for children, families and the community as a whole that a group of leaders is working collectively to improve. For example: “Residents with good jobs,” “Children ready for school,” or “A safe and clean neighborhood”.",
         "I finally found some real salary data for physicians in Australia. This website outlines the different salary grades at the public hospitals in Queensland (keep in mind that Brisbane has a lower cost of living than Sydney or Melbourne): http://www.health.qld.gov.au/medical/md_rem_packages.asp. It seems like about what everybody's been saying here.",
         "86595",
         "tensor([[ 0.0424, -0.5220,  0.4039,  ...,  0.2128,  0.1357, -0.0685],\n        [ 0.1372, -0.5429,  0.1942,  ..., -0.5206,  0.2543, -0.2376],\n        [ 0.7096, -0.3907, -0.7100,  ...,  0.1420, -1.2771,  0.4431],\n        ...,\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])",
         "3",
         "tensor([[ 0.0448,  0.0507,  0.1943,  ...,  0.0591, -0.0396,  0.0403],\n        [-0.0344, -0.1390, -0.0023,  ...,  0.0437,  0.0702, -0.0028],\n        [-0.0655,  0.1125,  0.1393,  ..., -0.0330,  0.0924, -0.0014],\n        ...,\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])",
         "110",
         "tensor([[ 0.0302,  0.4461,  0.4317,  ..., -0.7992,  0.8085,  0.3738],\n        [-0.5163, -0.2864, -0.1454,  ..., -0.6268,  0.9287,  0.5066],\n        [-0.0752, -0.6850,  0.5637,  ..., -0.3672,  0.3822, -0.1135],\n        ...,\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])",
         "67"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>positive_passage</th>\n",
       "      <th>negative_passage</th>\n",
       "      <th>negative_from_query_id</th>\n",
       "      <th>query_emb</th>\n",
       "      <th>query_length</th>\n",
       "      <th>pos_emb</th>\n",
       "      <th>pos_length</th>\n",
       "      <th>neg_emb</th>\n",
       "      <th>neg_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19699</td>\n",
       "      <td>what is rba</td>\n",
       "      <td>Results-Based Accountability® (also known as R...</td>\n",
       "      <td>I finally found some real salary data for phys...</td>\n",
       "      <td>86595</td>\n",
       "      <td>[[tensor(0.0424), tensor(-0.5220), tensor(0.40...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[tensor(0.0448), tensor(0.0507), tensor(0.194...</td>\n",
       "      <td>110</td>\n",
       "      <td>[[tensor(0.0302), tensor(0.4461), tensor(0.431...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id        query                                   positive_passage  \\\n",
       "0     19699  what is rba  Results-Based Accountability® (also known as R...   \n",
       "\n",
       "                                    negative_passage  negative_from_query_id  \\\n",
       "0  I finally found some real salary data for phys...                   86595   \n",
       "\n",
       "                                           query_emb  query_length  \\\n",
       "0  [[tensor(0.0424), tensor(-0.5220), tensor(0.40...             3   \n",
       "\n",
       "                                             pos_emb  pos_length  \\\n",
       "0  [[tensor(0.0448), tensor(0.0507), tensor(0.194...         110   \n",
       "\n",
       "                                             neg_emb  neg_length  \n",
       "0  [[tensor(0.0302), tensor(0.4461), tensor(0.431...          67  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_soft_neg_ext[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbbd3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the dataframe using apply\n",
    "print(\"Calculating embeddings... This may take a while depending on dataframe size.\")\n",
    "embeddings_padded = df_hard_neg.progress_apply(\n",
    "    lambda row: calculate_embeddings(row, word_to_idx, embeddings), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Join the similarities to the dataframe\n",
    "df_hard_neg_ext = pd.concat([df_hard_neg, embeddings_padded], axis=1)\n",
    "print(df_hard_neg_ext.head())\n",
    "# Show a sample of the results\n",
    "#print(df_hard_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].head())\n",
    "\n",
    "#print(df_hard_neg_ext[['query_pos_sim', 'query_neg_sim', 'pos_neg_sim']].mean())\n",
    "\n",
    "# Calculate how often the positive passage is ranked higher than negative\n",
    "#higher_count = (df_hard_neg_ext['query_pos_sim'] > df_hard_neg_ext['query_neg_sim']).sum()\n",
    "#total = len(df_hard_neg_ext)\n",
    "#print(f\"\\nPositive passage ranked higher than negative: {higher_count} out of {total} ({higher_count/total:.2%})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cea888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_neg_ext = pd.concat([df_soft_neg_ext, df_hard_neg_ext])\n",
    "df_all_neg_ext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "766f3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrames to pickle format\n",
    "df_soft_neg_ext.to_pickle(\"downloaded_model/df_soft_neg_ext.pkl\")\n",
    "#df_hard_neg_ext.to_pickle(\"downloaded_model/df_hard_neg_ext.pkl\")\n",
    "#df_all_neg_ext.to_pickle(\"downloaded_model/df_all_neg_ext.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02765d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a DataFrame from pickle if the file exists\n",
    "def load_df_if_exists(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        return pd.read_pickle(file_path)\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "# Load DataFrames\n",
    "df_soft_neg_ext = load_df_if_exists(\"downloaded_model/df_soft_neg_ext.pkl\")\n",
    "#df_hard_neg_ext = load_df_if_exists(\"downloaded_model/df_hard_neg_ext.pkl\")\n",
    "#df_all_neg_ext = load_df_if_exists(\"downloaded_model/df_all_neg_ext.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b9f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soft_neg_ext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Create packed sequences for RNN processing\n",
    "#packed_queries, packed_positives, packed_negatives = create_packed_batch(df_all_neg_ext)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd683001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Feed packed sequences to your RNN models\n",
    "# query_outputs, query_hidden =your_query_rnn(packed_queries)\n",
    "# pos_outputs, pos_hidden = your_document_rnn(packed_positives)\n",
    "# neg_outputs, neg_hidden = your_document_rnn(packed_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e0660e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/MLX_Week2/wandb/run-20250424_174424-x5ie5g41</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/x5ie5g41' target=\"_blank\">hyperparameter-tuning-20250424-174424</a></strong> to <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/x5ie5g41' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/x5ie5g41</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splits: Train=47822 | Validation=15941 | Test=15941\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hyperparameter-tuning-20250424-174424</strong> at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/x5ie5g41' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/x5ie5g41</a><br> View project at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_174424-x5ie5g41/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/MLX_Week2/wandb/run-20250424_174424-bqyxg7ch</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/bqyxg7ch' target=\"_blank\">dim100_batch512_hidden100_layers1_20250424-174424</a></strong> to <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/bqyxg7ch' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/bqyxg7ch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/MLX_Week2/mlx_env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training with: output_dim=100, batch_size=512, gru_hidden_dim=100, num_layers=1, dropout=0.1, lr=0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 10.82it/s]\n",
      "Epoch 1/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.1607, Val Loss: 0.1335, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 11.07it/s]\n",
      "Epoch 2/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.1218, Val Loss: 0.1128, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 11.72it/s]\n",
      "Epoch 3/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.0970, Val Loss: 0.0973, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 11.35it/s]\n",
      "Epoch 4/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.0798, Val Loss: 0.0867, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 11.19it/s]\n",
      "Epoch 5/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.0691, Val Loss: 0.0821, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 11.38it/s]\n",
      "Epoch 6/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.0587, Val Loss: 0.0774, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 11.47it/s]\n",
      "Epoch 7/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.0517, Val Loss: 0.0757, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 10.89it/s]\n",
      "Epoch 8/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.0445, Val Loss: 0.0719, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 11.64it/s]\n",
      "Epoch 9/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0392, Val Loss: 0.0731, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 (Train): 100%|██████████| 94/94 [00:08<00:00, 10.59it/s]\n",
      "Epoch 10/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0346, Val Loss: 0.0729, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▄▄▃▂▂▂▁▁</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_loss</td><td>0.03456</td></tr><tr><td>val_loss</td><td>0.0729</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dim100_batch512_hidden100_layers1_20250424-174424</strong> at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/bqyxg7ch' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/bqyxg7ch</a><br> View project at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_174424-bqyxg7ch/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/MLX_Week2/wandb/run-20250424_174630-iuga6o12</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/iuga6o12' target=\"_blank\">dim100_batch512_hidden200_layers1_20250424-174424</a></strong> to <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/iuga6o12' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/iuga6o12</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/MLX_Week2/mlx_env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training with: output_dim=100, batch_size=512, gru_hidden_dim=200, num_layers=1, dropout=0.1, lr=0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Train): 100%|██████████| 94/94 [00:11<00:00,  8.10it/s]\n",
      "Epoch 1/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.1596, Val Loss: 0.1489, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 (Train): 100%|██████████| 94/94 [00:11<00:00,  7.99it/s]\n",
      "Epoch 2/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.1280, Val Loss: 0.1193, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 (Train): 100%|██████████| 94/94 [00:11<00:00,  8.24it/s]\n",
      "Epoch 3/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.1065, Val Loss: 0.1006, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 (Train): 100%|██████████| 94/94 [00:11<00:00,  8.12it/s]\n",
      "Epoch 4/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.0892, Val Loss: 0.0908, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 (Train): 100%|██████████| 94/94 [00:11<00:00,  8.21it/s]\n",
      "Epoch 5/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.0777, Val Loss: 0.0862, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 (Train): 100%|██████████| 94/94 [00:11<00:00,  8.26it/s]\n",
      "Epoch 6/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.0665, Val Loss: 0.0844, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 (Train): 100%|██████████| 94/94 [00:12<00:00,  7.45it/s]\n",
      "Epoch 7/10 (Val): 100%|██████████| 32/32 [00:05<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.0593, Val Loss: 0.0799, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 (Train): 100%|██████████| 94/94 [00:13<00:00,  7.20it/s]\n",
      "Epoch 8/10 (Val): 100%|██████████| 32/32 [00:05<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.0513, Val Loss: 0.0786, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 (Train): 100%|██████████| 94/94 [00:14<00:00,  6.63it/s]\n",
      "Epoch 9/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0449, Val Loss: 0.0797, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 (Train): 100%|██████████| 94/94 [00:10<00:00,  8.84it/s]\n",
      "Epoch 10/10 (Val): 100%|██████████| 32/32 [00:04<00:00,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0391, Val Loss: 0.0775, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_loss</td><td>0.03914</td></tr><tr><td>val_loss</td><td>0.07751</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dim100_batch512_hidden200_layers1_20250424-174424</strong> at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/iuga6o12' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/iuga6o12</a><br> View project at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_174630-iuga6o12/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/MLX_Week2/wandb/run-20250424_174919-ayo3imz6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ayo3imz6' target=\"_blank\">dim100_batch1024_hidden100_layers1_20250424-174424</a></strong> to <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ayo3imz6' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ayo3imz6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/MLX_Week2/mlx_env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training with: output_dim=100, batch_size=1024, gru_hidden_dim=100, num_layers=1, dropout=0.1, lr=0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.59it/s]\n",
      "Epoch 1/10 (Val): 100%|██████████| 16/16 [00:04<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.1750, Val Loss: 0.1490, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.00it/s]\n",
      "Epoch 2/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.1372, Val Loss: 0.1300, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.56it/s]\n",
      "Epoch 3/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.1200, Val Loss: 0.1196, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.20it/s]\n",
      "Epoch 4/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.1048, Val Loss: 0.1049, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.63it/s]\n",
      "Epoch 5/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.0900, Val Loss: 0.0983, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.56it/s]\n",
      "Epoch 6/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.0802, Val Loss: 0.0899, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.28it/s]\n",
      "Epoch 7/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.0714, Val Loss: 0.0868, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.58it/s]\n",
      "Epoch 8/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.0638, Val Loss: 0.0831, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.59it/s]\n",
      "Epoch 9/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0569, Val Loss: 0.0839, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 (Train): 100%|██████████| 47/47 [00:07<00:00,  6.58it/s]\n",
      "Epoch 10/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0512, Val Loss: 0.0793, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_loss</td><td>0.05122</td></tr><tr><td>val_loss</td><td>0.07929</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dim100_batch1024_hidden100_layers1_20250424-174424</strong> at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ayo3imz6' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ayo3imz6</a><br> View project at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_174919-ayo3imz6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/MLX_Week2/wandb/run-20250424_175113-teeomm0j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/teeomm0j' target=\"_blank\">dim100_batch1024_hidden200_layers1_20250424-174424</a></strong> to <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/teeomm0j' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/teeomm0j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/MLX_Week2/mlx_env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training with: output_dim=100, batch_size=1024, gru_hidden_dim=200, num_layers=1, dropout=0.1, lr=0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.42it/s]\n",
      "Epoch 1/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.1720, Val Loss: 0.1511, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.47it/s]\n",
      "Epoch 2/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.1487, Val Loss: 0.1393, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.48it/s]\n",
      "Epoch 3/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.1343, Val Loss: 0.1313, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.62it/s]\n",
      "Epoch 4/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.1297, Val Loss: 0.1269, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.54it/s]\n",
      "Epoch 5/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.1269, Val Loss: 0.1228, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.51it/s]\n",
      "Epoch 6/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.1151, Val Loss: 0.1174, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.52it/s]\n",
      "Epoch 7/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.1097, Val Loss: 0.1073, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.61it/s]\n",
      "Epoch 8/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.1002, Val Loss: 0.1003, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.55it/s]\n",
      "Epoch 9/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0948, Val Loss: 0.1016, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 (Train): 100%|██████████| 47/47 [00:08<00:00,  5.55it/s]\n",
      "Epoch 10/10 (Val): 100%|██████████| 16/16 [00:03<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0888, Val Loss: 0.0982, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▂▂▁</td></tr><tr><td>val_loss</td><td>█▆▅▅▄▄▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_loss</td><td>0.08883</td></tr><tr><td>val_loss</td><td>0.09819</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dim100_batch1024_hidden200_layers1_20250424-174424</strong> at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/teeomm0j' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/teeomm0j</a><br> View project at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_175113-teeomm0j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best hyperparameters:\n",
      "Output dimension: 100\n",
      "Batch size: 512\n",
      "GRU hidden dimension: 100\n",
      "Number of GRU layers: 1\n",
      "Dropout: 0.1\n",
      "Learning rate: 0.001\n",
      "Validation Loss: 0.0719\n",
      "\n",
      "\n",
      "Training final model with best hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 11.69it/s]\n",
      "Epoch 1/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.1546, Val Loss: 0.1295, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 (Train): 100%|██████████| 125/125 [00:09<00:00, 12.63it/s]\n",
      "Epoch 2/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.1176, Val Loss: 0.1054, LR: 0.001000\n",
      "New best model saved with validation loss: 0.1054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.47it/s]\n",
      "Epoch 3/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.0938, Val Loss: 0.0884, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.37it/s]\n",
      "Epoch 4/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.0780, Val Loss: 0.0792, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.37it/s]\n",
      "Epoch 5/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.0676, Val Loss: 0.0753, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.33it/s]\n",
      "Epoch 6/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.0587, Val Loss: 0.0707, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.26it/s]\n",
      "Epoch 7/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.0524, Val Loss: 0.0669, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.14it/s]\n",
      "Epoch 8/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.0452, Val Loss: 0.0656, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.48it/s]\n",
      "Epoch 9/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0392, Val Loss: 0.0651, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 (Train): 100%|██████████| 125/125 [00:10<00:00, 12.45it/s]\n",
      "Epoch 10/10 (Val): 100%|██████████| 32/32 [00:03<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0346, Val Loss: 0.0636, LR: 0.001000\n",
      "New best model saved with validation loss: 0.0636\n",
      "Final model saved at: checkpoints/final_gru_model_20250424-174424/final_gru_model_20250424-174424.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/MLX_Week2/wandb/run-20250424_175537-ru8xhh4d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ru8xhh4d' target=\"_blank\">final_model_20250424-174424</a></strong> to <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ru8xhh4d' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ru8xhh4d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">final_model_20250424-174424</strong> at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ru8xhh4d' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model/runs/ru8xhh4d</a><br> View project at: <a href='https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model' target=\"_blank\">https://wandb.ai/nnamdi-odozi-ave-actuaries/gru-twin-tower-model</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_175537-ru8xhh4d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'output_dim': 100,\n",
       "  'batch_size': 512,\n",
       "  'gru_hidden_dim': 100,\n",
       "  'num_layers': 1,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.001,\n",
       "  'val_loss': 0.07193102573929298},\n",
       " GRUTwinTowerModel(\n",
       "   (query_encoder): BidirectionalGRU(\n",
       "     (gru): GRU(100, 100, batch_first=True, bidirectional=True)\n",
       "   )\n",
       "   (doc_encoder): BidirectionalGRU(\n",
       "     (gru): GRU(100, 100, batch_first=True, bidirectional=True)\n",
       "   )\n",
       "   (query_tower): QryTower(\n",
       "     (fc1): Linear(in_features=200, out_features=128, bias=True)\n",
       "     (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "     (fc3): Linear(in_features=64, out_features=100, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (doc_tower): DocTower(\n",
       "     (fc1): Linear(in_features=200, out_features=128, bias=True)\n",
       "     (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "     (fc3): Linear(in_features=64, out_features=100, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hyperparameter_tuning(df_soft_neg_ext, output_dims=[100], batch_sizes=[512, 1024], gru_hidden_dims=[100,200], \n",
    "                         num_layers=[1], dropouts=[0.1], learning_rates=[1e-3], \n",
    "                         epochs=10, log_wandb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba3edcd",
   "metadata": {},
   "source": [
    "### Twin Tower Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05391efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = os.path.join(\"checkpoints\\final_gru_model_20250424-152045\\final_gru_model_20250424-152045.pt\")\n",
    "# print(f\"Loading model from: {model_path}\")\n",
    "    \n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = torch.load(model_path, map_location=torch.to(device))\n",
    "# print(\"Loaded complete model\")\n",
    "\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b981b95a",
   "metadata": {},
   "outputs": [
    {
     "ename": "CommError",
     "evalue": "Invalid artifact path: nnamdi-odozi-ave-actuaries/gru-twin-tower-model/artifacts/model/final_gru_model_20250424-174424/v0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnamd\\OneDrive\\Python_learning\\MLX\\MLX_Week2\\mlx_env\\Lib\\site-packages\\wandb\\apis\\normalize.py:25\u001b[39m, in \u001b[36mnormalize_exceptions.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnamd\\OneDrive\\Python_learning\\MLX\\MLX_Week2\\mlx_env\\Lib\\site-packages\\wandb\\apis\\public\\api.py:1267\u001b[39m, in \u001b[36mApi._artifact\u001b[39m\u001b[34m(self, name, type, enable_tracking)\u001b[39m\n\u001b[32m   1266\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou must specify name= to fetch an artifact.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1267\u001b[39m entity, project, artifact_name = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_artifact_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1269\u001b[39m \u001b[38;5;66;03m# If its an Registry artifact, the entity is an org instead\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnamd\\OneDrive\\Python_learning\\MLX\\MLX_Week2\\mlx_env\\Lib\\site-packages\\wandb\\apis\\public\\api.py:754\u001b[39m, in \u001b[36mApi._parse_artifact_path\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    753\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parts) > \u001b[32m3\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m754\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid artifact path: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(path))\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parts) == \u001b[32m1\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: Invalid artifact path: nnamdi-odozi-ave-actuaries/gru-twin-tower-model/artifacts/model/final_gru_model_20250424-174424/v0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mCommError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Loading the pre-trained model from WandB\u001b[39;00m\n\u001b[32m      2\u001b[39m api = wandb.Api()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m artifact = \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43martifact\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnnamdi-odozi-ave-actuaries/gru-twin-tower-model/artifacts/model/final_gru_model_20250424-174424/v0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m artifact_dir = artifact.download()\n\u001b[32m      5\u001b[39m model_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/model.pt\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnamd\\OneDrive\\Python_learning\\MLX\\MLX_Week2\\mlx_env\\Lib\\site-packages\\wandb\\apis\\normalize.py:65\u001b[39m, in \u001b[36mnormalize_exceptions.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     61\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CommError(message, err.last_exception).with_traceback(\n\u001b[32m     62\u001b[39m             sys.exc_info()[\u001b[32m2\u001b[39m]\n\u001b[32m     63\u001b[39m         )\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Error \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# gql raises server errors with dict's as strings...\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(err.args) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnamd\\OneDrive\\Python_learning\\MLX\\MLX_Week2\\mlx_env\\Lib\\site-packages\\wandb\\apis\\normalize.py:25\u001b[39m, in \u001b[36mnormalize_exceptions.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m message = \u001b[33m\"\u001b[39m\u001b[33mWhoa, you found a bug.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m     28\u001b[39m     errors = parse_backend_error_messages(error.response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnamd\\OneDrive\\Python_learning\\MLX\\MLX_Week2\\mlx_env\\Lib\\site-packages\\wandb\\apis\\public\\api.py:1320\u001b[39m, in \u001b[36mApi.artifact\u001b[39m\u001b[34m(self, name, type)\u001b[39m\n\u001b[32m   1298\u001b[39m \u001b[38;5;129m@normalize_exceptions\u001b[39m\n\u001b[32m   1299\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34martifact\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1300\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a single artifact by parsing path in the form `project/name` or `entity/project/name`.\u001b[39;00m\n\u001b[32m   1301\u001b[39m \n\u001b[32m   1302\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1318\u001b[39m \u001b[33;03m    This method is intended for external use only. Do not call `api.artifact()` within the wandb repository code.\u001b[39;00m\n\u001b[32m   1319\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1320\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_tracking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnamd\\OneDrive\\Python_learning\\MLX\\MLX_Week2\\mlx_env\\Lib\\site-packages\\wandb\\apis\\normalize.py:79\u001b[39m, in \u001b[36mnormalize_exceptions.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CommError(message, err).with_traceback(sys.exc_info()[\u001b[32m2\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnamd\\OneDrive\\Python_learning\\MLX\\MLX_Week2\\mlx_env\\Lib\\site-packages\\wandb\\apis\\normalize.py:25\u001b[39m, in \u001b[36mnormalize_exceptions.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m message = \u001b[33m\"\u001b[39m\u001b[33mWhoa, you found a bug.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m     28\u001b[39m     errors = parse_backend_error_messages(error.response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnamd\\OneDrive\\Python_learning\\MLX\\MLX_Week2\\mlx_env\\Lib\\site-packages\\wandb\\apis\\public\\api.py:1267\u001b[39m, in \u001b[36mApi._artifact\u001b[39m\u001b[34m(self, name, type, enable_tracking)\u001b[39m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1266\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou must specify name= to fetch an artifact.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1267\u001b[39m entity, project, artifact_name = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_artifact_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1269\u001b[39m \u001b[38;5;66;03m# If its an Registry artifact, the entity is an org instead\u001b[39;00m\n\u001b[32m   1270\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_artifact_registry_project(project):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nnamd\\OneDrive\\Python_learning\\MLX\\MLX_Week2\\mlx_env\\Lib\\site-packages\\wandb\\apis\\public\\api.py:754\u001b[39m, in \u001b[36mApi._parse_artifact_path\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    752\u001b[39m parts = path.split(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    753\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parts) > \u001b[32m3\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m754\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid artifact path: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(path))\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parts) == \u001b[32m1\u001b[39m:\n\u001b[32m    756\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m entity, project, path + full_alias\n",
      "\u001b[31mCommError\u001b[39m: Invalid artifact path: nnamdi-odozi-ave-actuaries/gru-twin-tower-model/artifacts/model/final_gru_model_20250424-174424/v0"
     ]
    }
   ],
   "source": [
    "# Loading the pre-trained model from WandB\n",
    "api = wandb.Api()\n",
    "artifact = api.artifact(\"nnamdi-odozi-ave-actuaries/gru-twin-tower-model/artifacts/model/final_gru_model_20250424-174424/v0\")\n",
    "artifact_dir = artifact.download()\n",
    "model_path = f\"{artifact_dir}/model.pt\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Try loading model\n",
    "try:\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "except:\n",
    "    model = GRUTwinTowerModel(embedding_dim=100, gru_hidden_dim=128, output_dim=100, \n",
    "                             num_layers=1, dropout=0.1)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8847a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Test with consecutive rows - just use a slice directly\n",
    "df_slice = df_soft_neg_ext[0:3]  # Use any 3 consecutive rows\n",
    "\n",
    "# Process dataframe slice\n",
    "with torch.no_grad():\n",
    "    # Move everything to device\n",
    "    query_embs = torch.stack(df_slice['query_emb'].tolist()).to(device)\n",
    "    query_lens = torch.tensor(df_slice['query_length'].tolist()).to(device)\n",
    "    pos_embs = torch.stack(df_slice['pos_emb'].tolist()).to(device)\n",
    "    pos_lens = torch.tensor(df_slice['pos_length'].tolist()).to(device)\n",
    "    \n",
    "    # Get encodings for all rows at once\n",
    "    query_vecs, doc_vecs = model(query_embs, query_lens, pos_embs, pos_lens)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    sims = torch.nn.functional.cosine_similarity(query_vecs, doc_vecs, dim=1)\n",
    "    \n",
    "print(\"Similarities:\", sims.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd960918",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cosine_similarity(): argument 'x1' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m doc_emb = text_to_embeddings(doc_test, word_to_idx, embeddings, is_query=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      7\u001b[39m  \u001b[38;5;66;03m# Calculate similarities\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m sims = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSimilarities:\u001b[39m\u001b[33m\"\u001b[39m, sims.cpu().numpy())\n",
      "\u001b[31mTypeError\u001b[39m: cosine_similarity(): argument 'x1' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "#with a random sentence:\n",
    "query_test = \"This is RBA\"\n",
    "doc_test = \"This is RBA\"\n",
    "query_emb = text_to_embeddings(query_test, word_to_idx, embeddings, is_query=True)\n",
    "doc_emb = text_to_embeddings(doc_test, word_to_idx, embeddings, is_query=False)\n",
    "\n",
    " # Calculate similarities\n",
    "sims = torch.nn.functional.cosine_similarity(query_emb, doc_emb, dim=1)\n",
    "    \n",
    "print(\"Similarities:\", sims.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e3b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Query-only inference using just dataframe columns \n",
    "query_row = df_soft_neg_ext[0]  # Use any row\n",
    "test_query_emb = query_row['query_emb'].unsqueeze(0).to(device)\n",
    "test_query_len = torch.tensor([query_row['query_length']]).to(device)\n",
    "\n",
    "# Just run through query encoder and tower\n",
    "with torch.no_grad():\n",
    "    query_encoded = model.query_encoder(test_query_emb, test_query_len)\n",
    "    query_vector = model.query_tower(query_encoded)\n",
    "    query_vector = torch.nn.functional.normalize(query_vector, p=2, dim=1) #I don't think this is needed, but let's keep it for now\n",
    "\n",
    "print(\"Query vector shape:\", query_vector.shape)\n",
    "print(\"Values:\", query_vector[0, :5].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239cc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tower instances\n",
    "#qryTower = QryTower()\n",
    "#docTower = DocTower()\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 128\n",
    "num_epochs = 1 # adjust num of epochs here\n",
    "dataset_size = len(df_all_neg_ext)  # or len(df_hard_neg_ext) depending on the dataset you want to use\n",
    "steps_per_epoch = dataset_size // batch_size\n",
    "total_steps = steps_per_epoch * num_epochs\n",
    "learning_rate = 1e-3\n",
    "embedding_dim = 100 #changed for glove \n",
    "margin = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = TripletEmbeddingDataset(df_all_neg_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7753f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    #num_workers=2,  # Adjust based on your machine's capabilities\n",
    "    pin_memory=True  # Set to True if using GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = torch.randn(batch_size, embedding_dim)  # Query embeddings\n",
    "pos = torch.randn(batch_size, embedding_dim)  # Positive doc embeddings\n",
    "neg = torch.randn(batch_size, embedding_dim)  # Negative doc embeddings\n",
    "\n",
    "#qry = df1['q']\n",
    "\n",
    "\n",
    "# Set up the AdamW optimizer\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': qryTower.parameters()},\n",
    "    {'params': docTower.parameters()}\n",
    "], lr=learning_rate)\n",
    "\n",
    "# Add learning rate scheduler (ReduceLROnPlateau)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',       # Reduce LR when monitored value stops decreasing\n",
    "    factor=0.5,       # Multiply LR by this factor when reducing\n",
    "    patience=2,       # Number of epochs with no improvement after which LR will be reduced\n",
    "    verbose=True      # Print message when LR is reduced\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8531b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(qryTower, docTower, dataloader, device):\n",
    "    qryTower.eval()\n",
    "    docTower.eval()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        # Get embeddings from batch\n",
    "        query_emb = batch['query']\n",
    "        pos_emb = batch['positive']\n",
    "        neg_emb = batch['negative']\n",
    "        \n",
    "        # Forward pass through towers\n",
    "        query_encoded = qryTower(query_emb)\n",
    "        pos_encoded = docTower(pos_emb)\n",
    "        neg_encoded = docTower(neg_emb)\n",
    "        \n",
    "        # Calculate similarities\n",
    "        pos_sim = torch.nn.functional.cosine_similarity(query_encoded, pos_encoded)\n",
    "        neg_sim = torch.nn.functional.cosine_similarity(query_encoded, neg_encoded)\n",
    "\n",
    "        correct += (pos_sim > neg_sim).sum().item()\n",
    "        total += batch['query'].size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"Eval Accuracy (query closer to pos than neg): {acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "total_loss = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53907333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Epoch {epoch+1}, Avg Loss: {total_loss / len(dataloader):.4f}\")\n",
    "evaluate_model(final_qry_tower, final_doc_tower, dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_emb = text_to_embeddings(\"What is RBA\", word_to_idx, embeddings)\n",
    "pos_emb = text_to_embeddings(\"What is RBA\", word_to_idx, embeddings)\n",
    "\n",
    "# Ensure tensors have at least two dimensions before applying mean\n",
    "if query_emb.dim() == 1:\n",
    "\tquery_emb = query_emb.unsqueeze(0)\n",
    "if pos_emb.dim() == 1:\n",
    "\tpos_emb = pos_emb.unsqueeze(0)\n",
    "\n",
    "query_emb = query_emb.mean(dim=0)\n",
    "pos_emb = pos_emb.mean(dim=0)\n",
    "\n",
    "print(torch.nn.functional.cosine_similarity(query_emb, pos_emb, dim=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_qry_tower.eval()\n",
    "final_doc_tower.eval()\n",
    "query_encoded = final_qry_tower(query_emb)\n",
    "pos_encoded = final_doc_tower(pos_emb)\n",
    "torch.nn.functional.cosine_similarity(query_encoded, pos_encoded, dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f33ed4bb",
   "metadata": {},
   "source": [
    "Download embedding model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "473c39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from model import CBOW\n",
    "\n",
    "# model withou title hackers\n",
    "model_path = hf_hub_download(repo_id=\"cocoritzy/cbow-upvotes_model\", filename=\"cbow_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc76062",
   "metadata": {},
   "source": [
    "Load model architecture and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b5614341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve checkpoint \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint = torch.load(model_path, map_location=device) #A checkpoint is a file that saves the state of your model (\n",
    "token_to_index = checkpoint[\"token_to_index\"]\n",
    "embedding_dim= checkpoint[\"embedding_dim\"]\n",
    "vocab_size = len(token_to_index)  # fill in actual size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c80eed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = CBOW(voc=vocab_size, emb=embedding_dim)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "model.eval()# it contains the model's parameters and other information needed to resume training or make predictions.\n",
    "embedding_layer = model.embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5869cbe",
   "metadata": {},
   "source": [
    "Load query and title documents - text hard and soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "11c23de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "df_hn = load_dataset(\"cocoritzy/week_2_triplet_dataset_hard_negatives\")\n",
    "df_sn = load_dataset(\"cocoritzy/week_2_triplet_dataset_soft_negatives\")\n",
    "# dataset = load_dataset(\"cocoritzy/week_2_triplet_dataset_hard_negatives\", split=\"train[:10%]\") # 10% of the datab\n",
    "df_hn = df_hn[\"train\"].to_pandas()\n",
    "df_sn = df_sn[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "08661520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>positive_passage</th>\n",
       "      <th>negative_passage</th>\n",
       "      <th>negative_from_query_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19699</td>\n",
       "      <td>what is rba</td>\n",
       "      <td>Results-Based Accountability® (also known as R...</td>\n",
       "      <td>I finally found some real salary data for phys...</td>\n",
       "      <td>86595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19700</td>\n",
       "      <td>was ronald reagan a democrat</td>\n",
       "      <td>From Wikipedia, the free encyclopedia. A Reaga...</td>\n",
       "      <td>The Pacific Ocean lies to the east while the S...</td>\n",
       "      <td>66360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19701</td>\n",
       "      <td>how long do you need for sydney and surroundin...</td>\n",
       "      <td>Sydney is the capital city of the Australian s...</td>\n",
       "      <td>Probiotics are found in foods such as yogurt, ...</td>\n",
       "      <td>88507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19702</td>\n",
       "      <td>price to install tile in shower</td>\n",
       "      <td>1 Install ceramic tile floor to match shower-A...</td>\n",
       "      <td>Iodine is critical to thyroid health and funct...</td>\n",
       "      <td>87550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19703</td>\n",
       "      <td>why conversion observed in body</td>\n",
       "      <td>Conversion disorder is a type of somatoform di...</td>\n",
       "      <td>The answer to the question how much does it co...</td>\n",
       "      <td>61479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79699</th>\n",
       "      <td>102124</td>\n",
       "      <td>meaning of propagation</td>\n",
       "      <td>definition of propagation the act or action of...</td>\n",
       "      <td>A minimum of two credits of laboratory science...</td>\n",
       "      <td>21857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79700</th>\n",
       "      <td>102125</td>\n",
       "      <td>do you have to do a phd to be a clinical psych...</td>\n",
       "      <td>The goal you choose will determine your path. ...</td>\n",
       "      <td>1 The mitochondria of eukaryotes evolved from ...</td>\n",
       "      <td>28764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79701</th>\n",
       "      <td>102126</td>\n",
       "      <td>what wine goes with oysters</td>\n",
       "      <td>You may also enjoy these other types of wine w...</td>\n",
       "      <td>Raynaud's (say ray-NOHZ) phenomenon is a probl...</td>\n",
       "      <td>42284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79702</th>\n",
       "      <td>102127</td>\n",
       "      <td>what strengths does lithium come in</td>\n",
       "      <td>Lithium 150 mg. Lithium (Eskalith ® , Eskalith...</td>\n",
       "      <td>While kids feel like they’ve been grownups for...</td>\n",
       "      <td>42891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79703</th>\n",
       "      <td>102128</td>\n",
       "      <td>what is polarity index definition</td>\n",
       "      <td>Polarity Index. Burdick &amp; Jackson solvents are...</td>\n",
       "      <td>Calculating Costs Per Inmate. According to the...</td>\n",
       "      <td>94401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79704 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       query_id                                              query  \\\n",
       "0         19699                                        what is rba   \n",
       "1         19700                       was ronald reagan a democrat   \n",
       "2         19701  how long do you need for sydney and surroundin...   \n",
       "3         19702                    price to install tile in shower   \n",
       "4         19703                    why conversion observed in body   \n",
       "...         ...                                                ...   \n",
       "79699    102124                             meaning of propagation   \n",
       "79700    102125  do you have to do a phd to be a clinical psych...   \n",
       "79701    102126                        what wine goes with oysters   \n",
       "79702    102127                what strengths does lithium come in   \n",
       "79703    102128                  what is polarity index definition   \n",
       "\n",
       "                                        positive_passage  \\\n",
       "0      Results-Based Accountability® (also known as R...   \n",
       "1      From Wikipedia, the free encyclopedia. A Reaga...   \n",
       "2      Sydney is the capital city of the Australian s...   \n",
       "3      1 Install ceramic tile floor to match shower-A...   \n",
       "4      Conversion disorder is a type of somatoform di...   \n",
       "...                                                  ...   \n",
       "79699  definition of propagation the act or action of...   \n",
       "79700  The goal you choose will determine your path. ...   \n",
       "79701  You may also enjoy these other types of wine w...   \n",
       "79702  Lithium 150 mg. Lithium (Eskalith ® , Eskalith...   \n",
       "79703  Polarity Index. Burdick & Jackson solvents are...   \n",
       "\n",
       "                                        negative_passage  \\\n",
       "0      I finally found some real salary data for phys...   \n",
       "1      The Pacific Ocean lies to the east while the S...   \n",
       "2      Probiotics are found in foods such as yogurt, ...   \n",
       "3      Iodine is critical to thyroid health and funct...   \n",
       "4      The answer to the question how much does it co...   \n",
       "...                                                  ...   \n",
       "79699  A minimum of two credits of laboratory science...   \n",
       "79700  1 The mitochondria of eukaryotes evolved from ...   \n",
       "79701  Raynaud's (say ray-NOHZ) phenomenon is a probl...   \n",
       "79702  While kids feel like they’ve been grownups for...   \n",
       "79703  Calculating Costs Per Inmate. According to the...   \n",
       "\n",
       "       negative_from_query_id  \n",
       "0                       86595  \n",
       "1                       66360  \n",
       "2                       88507  \n",
       "3                       87550  \n",
       "4                       61479  \n",
       "...                       ...  \n",
       "79699                   21857  \n",
       "79700                   28764  \n",
       "79701                   42284  \n",
       "79702                   42891  \n",
       "79703                   94401  \n",
       "\n",
       "[79704 rows x 5 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be87ec",
   "metadata": {},
   "source": [
    "split train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "133a75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split into training and test sets (e.g. 20% train, 2% test = 90% drop)\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df_sn,\n",
    "    train_size=0.20,\n",
    "    test_size=0.02,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5a1f3c",
   "metadata": {},
   "source": [
    "Instantiate towers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "70812fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class QryTower(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class DocTower(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "qryTower = QryTower().to(device) #Initialize and move models to the right device\n",
    "docTower = DocTower().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1c821b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935722d",
   "metadata": {},
   "source": [
    "initiate class for data laoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "106a95b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # query/passage to average embedding \n",
    "# def title_to_embedding(words):\n",
    "#     tokens = words.lower().split()\n",
    "#     indices = [token_to_index.get(tok, 0) for tok in tokens]  # 0 for unknowns - get the value associated with the words\n",
    "\n",
    "#     indices_tensor = torch.tensor(indices, dtype=torch.long, device=device) # converts the list indices into a PyTorch tensors\n",
    "\n",
    "#     with torch.no_grad(): # This makes the code faster and uses less memory, because you're not training, just extracting embeddings.\n",
    "#         embeds = embedding_layer(indices_tensor) # [num_tokens, embedding_dim]\n",
    "#         return embeds.mean(dim=0) # average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4a7e398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, df, token_to_index, embedding_layer, device):\n",
    "        self.df = df\n",
    "        self.token_to_index = token_to_index\n",
    "        self.embedding_layer = embedding_layer\n",
    "        self.device = device\n",
    "\n",
    "    def title_to_embedding(self, words):\n",
    "        tokens = words.lower().split()\n",
    "        indices = [self.token_to_index.get(tok, 0) for tok in tokens]\n",
    "        indices_tensor = torch.tensor(indices, dtype=torch.long, device=self.device)\n",
    "        #with torch.no_grad():\n",
    "        embeds = self.embedding_layer(indices_tensor)\n",
    "        return embeds.mean(dim=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        query = self.title_to_embedding(row[\"query\"])\n",
    "        pos = self.title_to_embedding(row[\"positive_passage\"])\n",
    "        neg = self.title_to_embedding(row[\"negative_passage\"])\n",
    "        return query, pos, neg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4caa4c3",
   "metadata": {},
   "source": [
    "training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cfbfc7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "triplet_dataset = TripletDataset(train_df, token_to_index, embedding_layer, device)\n",
    "dataloader = DataLoader(triplet_dataset, batch_size=128, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4c21ffde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query shape: torch.Size([128, 100])\n",
      "positive shape: torch.Size([128, 100])\n",
      "negative shape: torch.Size([128, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for query, pos, neg in dataloader:\n",
    "    print(\"query shape:\", query.shape)\n",
    "    print(\"positive shape:\", pos.shape)\n",
    "    print(\"negative shape:\", neg.shape)\n",
    "    break\n",
    "len(dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23929563",
   "metadata": {},
   "source": [
    "Pass embeddings through the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac04dbf",
   "metadata": {},
   "source": [
    "define loss function and optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "684a7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "\n",
    "# # Cosine similarities along dim=1 (batch)\n",
    "# dst_pos = F.cosine_similarity(query, pos, dim=1)\n",
    "# dst_neg = F.cosine_similarity(query, neg, dim=1)\n",
    "\n",
    "# dst_dif = dst_pos - dst_neg\n",
    "# margin = 0.2\n",
    "\n",
    "# loss = torch.clamp(margin - dst_dif, min=0).mean()\n",
    "# #loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d330a3af",
   "metadata": {},
   "source": [
    "training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bb3d9988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6182\n",
      "Epoch 2, Loss: 0.6158\n",
      "Epoch 3, Loss: 0.6161\n",
      "Epoch 4, Loss: 0.6185\n",
      "Epoch 5, Loss: 0.6196\n",
      "Epoch 6, Loss: 0.6201\n",
      "Epoch 7, Loss: 0.6219\n",
      "Epoch 8, Loss: 0.6237\n",
      "Epoch 9, Loss: 0.6233\n",
      "Epoch 10, Loss: 0.6166\n",
      "Epoch 11, Loss: 0.6136\n",
      "Epoch 12, Loss: 0.6122\n",
      "Epoch 13, Loss: 0.6050\n",
      "Epoch 14, Loss: 0.6064\n",
      "Epoch 15, Loss: 0.6070\n",
      "Epoch 16, Loss: 0.6076\n",
      "Epoch 17, Loss: 0.6084\n",
      "Epoch 18, Loss: 0.6075\n",
      "Epoch 19, Loss: 0.6125\n",
      "Epoch 20, Loss: 0.6136\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Set models to training mode\n",
    "qryTower.train()\n",
    "docTower.train()\n",
    "\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for query_vecs, pos_vecs, neg_vecs in dataloader:\n",
    "        query_vecs = query_vecs.to(device)\n",
    "        pos_vecs = pos_vecs.to(device)\n",
    "        neg_vecs = neg_vecs.to(device)\n",
    "\n",
    "        qry = qryTower(query_vecs)\n",
    "        pos = docTower(pos_vecs)\n",
    "        neg = docTower(neg_vecs)\n",
    "\n",
    "        dst_pos = F.cosine_similarity(qry, pos, dim=1)\n",
    "        dst_neg = F.cosine_similarity(qry, neg, dim=1)\n",
    "\n",
    "        margin = 0.2\n",
    "        loss = torch.clamp(margin - (dst_pos - dst_neg), min=0).mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "29fc7aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1882\n"
     ]
    }
   ],
   "source": [
    "qryTower.eval()\n",
    "docTower.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for query_vecs, pos_vecs, neg_vecs in dataloader:\n",
    "        query_vecs = query_vecs.to(device)\n",
    "        pos_vecs = pos_vecs.to(device)\n",
    "        neg_vecs = neg_vecs.to(device)\n",
    "\n",
    "        qry = qryTower(query_vecs)\n",
    "        pos = docTower(pos_vecs)\n",
    "        neg = docTower(neg_vecs)\n",
    "\n",
    "        dst_pos = F.cosine_similarity(qry, pos, dim=1)\n",
    "        dst_neg = F.cosine_similarity(qry, neg, dim=1)\n",
    "\n",
    "        correct += (dst_pos > dst_neg).sum().item()\n",
    "        total += query_vecs.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b9573f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def word_cosine_similarity(word1, word2, token_to_index, embedding_layer, device):\n",
    "    idx1 = torch.tensor([token_to_index.get(word1.lower(), 0)], dtype=torch.long, device=device)\n",
    "    idx2 = torch.tensor([token_to_index.get(word2.lower(), 0)], dtype=torch.long, device=device)\n",
    "\n",
    "    emb1 = embedding_layer(idx1)  # shape [1, embedding_dim]\n",
    "    emb2 = embedding_layer(idx2)\n",
    "\n",
    "    similarity = F.cosine_similarity(emb1, emb2).item()  # scalar\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "35e47706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'cat' and 'dog': 0.6890\n"
     ]
    }
   ],
   "source": [
    "sim = word_cosine_similarity(\"good\", \"bad\", token_to_index, embedding_layer, device)\n",
    "print(f\"Cosine similarity between 'cat' and 'dog': {sim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e5d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

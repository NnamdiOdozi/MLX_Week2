{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0231b208",
   "metadata": {},
   "source": [
    "# Download embeddings model from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c2c76e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/MLX_Week2-1/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbffa35",
   "metadata": {},
   "source": [
    "## get model for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aa06c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from model import CBOW\n",
    "\n",
    "# model withou title hackers\n",
    "model_path = hf_hub_download(repo_id=\"cocoritzy/cbow-upvotes_model\", filename=\"cbow_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07cb60f",
   "metadata": {},
   "source": [
    "## retreive the checkpoints --> A checkpoint is a file that saves the state of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "48427377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint = torch.load(model_path, map_location=device) #A checkpoint is a file that saves the state of your model (\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7cc96c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('embeddings.weight', tensor([[-6.4979e-01, -5.7941e-01,  6.6106e-01,  ..., -2.2381e+00,\n",
      "         -4.7060e-04,  1.5041e-01],\n",
      "        [-4.9834e-01, -1.3562e+00,  5.9971e-02,  ...,  2.2810e-02,\n",
      "         -4.2601e+00,  1.6657e+00],\n",
      "        [-3.5826e-01,  1.8044e+00,  3.4292e-01,  ..., -4.9925e-01,\n",
      "          6.3616e-02, -2.0757e-01],\n",
      "        ...,\n",
      "        [ 3.0328e+00,  2.2346e+00, -4.0947e+00,  ...,  1.5389e+00,\n",
      "         -3.1774e+00,  1.5126e+00],\n",
      "        [ 9.5289e-01, -7.5809e-01, -1.0489e+00,  ...,  2.7495e+00,\n",
      "         -2.2415e+00,  6.3896e-01],\n",
      "        [ 6.0927e-01, -3.6017e-01, -2.4570e+00,  ...,  2.5984e+00,\n",
      "         -1.5189e+00, -1.4678e+00]], device='cuda:0')), ('linear.weight', tensor([[-0.9190, -3.4283, -1.5246,  ...,  0.7419,  2.3657, -0.5639],\n",
      "        [-0.9271, -3.3398, -1.2597,  ...,  0.3505,  2.7461, -0.6402],\n",
      "        [-1.0051, -3.6519, -1.2860,  ...,  0.3628,  2.5529, -0.4234],\n",
      "        ...,\n",
      "        [-1.0449, -2.6130, -1.2064,  ...,  0.3532,  2.4671, -0.5399],\n",
      "        [-0.7596, -3.6919, -1.1978,  ...,  0.1844,  2.4805, -0.5774],\n",
      "        [-0.6487, -3.7323, -1.4123,  ...,  0.1245,  2.9077, -0.6741]],\n",
      "       device='cuda:0')), ('linear.bias', tensor([ -1.7899,  -2.3857,  -2.0153,  ..., -16.6750, -17.6582, -16.5161],\n",
      "       device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0703d08a",
   "metadata": {},
   "source": [
    "## load the dimension - for embedding dim and vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a038b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "token_to_index = checkpoint[\"token_to_index\"]\n",
    "embedding_dim= checkpoint[\"embedding_dim\"]\n",
    "vocab_size = len(token_to_index)  # fill in actual size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6f1fe",
   "metadata": {},
   "source": [
    "# Load the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "75b3ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = CBOW(voc=vocab_size, emb=embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdae4a7",
   "metadata": {},
   "source": [
    "## load model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ae38d040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBOW(\n",
       "  (embeddings): Embedding(30000, 100)\n",
       "  (linear): Linear(in_features=100, out_features=30000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "model.eval()# it contains the model's parameters and other information needed to resume training or make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7961b8",
   "metadata": {},
   "source": [
    "# Load query and title documents - text hard and soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "40da2c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "df_hn = load_dataset(\"cocoritzy/week_2_triplet_dataset_hard_negatives\")\n",
    "df_sn = load_dataset(\"cocoritzy/week_2_triplet_dataset_soft_negatives\")\n",
    "# dataset = load_dataset(\"cocoritzy/week_2_triplet_dataset_hard_negatives\", split=\"train[:10%]\") # 10% of the data\n",
    "\n",
    "\n",
    "split_data_hn = df_hn[\"train\"].train_test_split(test_size=0.2, seed=42) # 80% train, 20% test\n",
    "split_data_sn = df_sn[\"train\"].train_test_split(test_size=0.2, seed=42) # 80% train, 20% test\n",
    "\n",
    "df_hn = split_data_hn[\"train\"].to_pandas()\n",
    "df_sf = split_data_sn[\"train\"].to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f8bcb9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                           63760\n",
       "unique                          63760\n",
       "top       why do atoms have no charge\n",
       "freq                                1\n",
       "Name: query, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hn['query'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597e86b3",
   "metadata": {},
   "source": [
    "# Convert title to embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a214749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = model.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c394b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_to_embedding(words):\n",
    "    tokens = words.lower().split()\n",
    "    indices = [token_to_index.get(tok, 0) for tok in tokens]  # 0 for unknowns - get the value associated with the words\n",
    "\n",
    "    indices_tensor = torch.tensor(indices, dtype=torch.long, device=device) # converts the list indices into a PyTorch tensors\n",
    "\n",
    "    with torch.no_grad(): # This makes the code faster and uses less memory, because you're not training, just extracting embeddings.\n",
    "        embeds = embedding_layer(indices_tensor) # [num_tokens, embedding_dim]\n",
    "        return embeds.mean(dim=0) # average pooling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d68fc",
   "metadata": {},
   "source": [
    "## little test on the side "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b36c4955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999998807907104 0.6890109777450562\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "query = df_hn.iloc[12][\"query\"]\n",
    "negative = df_hn.iloc[12][\"negative_passage\"]\n",
    "postive = df_hn.iloc[12][\"positive_passage\"]\n",
    "\n",
    "query_emb = title_to_embedding(\"bad\")\n",
    "negative_emb = title_to_embedding(\"good\")\n",
    "positive_emb = title_to_embedding(\"bad\")\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    return F.cosine_similarity(x.unsqueeze(0), y.unsqueeze(0)).item()\n",
    "\n",
    "sim_pos = cosine_similarity(query_emb, positive_emb)\n",
    "sim_neg = cosine_similarity(query_emb, negative_emb)\n",
    "print(sim_pos, sim_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f476f8",
   "metadata": {},
   "source": [
    "## apply it on all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fc502b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compute_similarity_from_row(row):\n",
    "    query_vec = title_to_embedding(row['query'])\n",
    "    pos_vec = title_to_embedding(row['positive_passage'])\n",
    "    neg_vec = title_to_embedding(row['negative_passage'])\n",
    "\n",
    "    sim_pos = F.cosine_similarity(query_vec.unsqueeze(0), pos_vec.unsqueeze(0)).item()\n",
    "    sim_neg = F.cosine_similarity(query_vec.unsqueeze(0), neg_vec.unsqueeze(0)).item()\n",
    "\n",
    "    return pd.Series({'sim_pos': sim_pos, 'sim_neg': sim_neg})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "edda2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hn[[\"sim_pos\", \"sim_neg\"]] = df_hn.apply(compute_similarity_from_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "86ce36d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5690401505646173\n"
     ]
    }
   ],
   "source": [
    "df_hn[\"correct\"] = df_hn[\"sim_pos\"] > df_hn[\"sim_neg\"]\n",
    "accuracy = df_hn[\"correct\"].mean()\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ed20ec3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>positive_passage</th>\n",
       "      <th>negative_passage</th>\n",
       "      <th>negative_index_in_group</th>\n",
       "      <th>sim_pos</th>\n",
       "      <th>sim_neg</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22392</td>\n",
       "      <td>is it okay to mix magnesium and cranberry when...</td>\n",
       "      <td>Cranberry has relatively high levels of oxalat...</td>\n",
       "      <td>However, studies suggest that cranberry does n...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.609932</td>\n",
       "      <td>0.633598</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41323</td>\n",
       "      <td>salary range associate professor</td>\n",
       "      <td>Associate Professor Salary. Associate Professo...</td>\n",
       "      <td>Professors in the United States are often vete...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.748564</td>\n",
       "      <td>0.125579</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42361</td>\n",
       "      <td>weather in tenerife in may</td>\n",
       "      <td>Below is the typical weather in Tenerife in Ma...</td>\n",
       "      <td>Weather in Tenerife in May. Home to some of Eu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277476</td>\n",
       "      <td>0.365389</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80083</td>\n",
       "      <td>what is morocco main language</td>\n",
       "      <td>The official language of Morocco is Arabic whi...</td>\n",
       "      <td>Arabic, along with Berber, is one of two Moroc...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.316427</td>\n",
       "      <td>0.051429</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54985</td>\n",
       "      <td>tdap vaccine age limit</td>\n",
       "      <td>DTaP is approved for children under age 7. Tda...</td>\n",
       "      <td>1 Krishnarajah G. Cost-effectiveness analysis ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451703</td>\n",
       "      <td>0.189826</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                                              query  \\\n",
       "0     22392  is it okay to mix magnesium and cranberry when...   \n",
       "1     41323                   salary range associate professor   \n",
       "2     42361                         weather in tenerife in may   \n",
       "3     80083                      what is morocco main language   \n",
       "4     54985                             tdap vaccine age limit   \n",
       "\n",
       "                                    positive_passage  \\\n",
       "0  Cranberry has relatively high levels of oxalat...   \n",
       "1  Associate Professor Salary. Associate Professo...   \n",
       "2  Below is the typical weather in Tenerife in Ma...   \n",
       "3  The official language of Morocco is Arabic whi...   \n",
       "4  DTaP is approved for children under age 7. Tda...   \n",
       "\n",
       "                                    negative_passage  negative_index_in_group  \\\n",
       "0  However, studies suggest that cranberry does n...                        8   \n",
       "1  Professors in the United States are often vete...                        1   \n",
       "2  Weather in Tenerife in May. Home to some of Eu...                        1   \n",
       "3  Arabic, along with Berber, is one of two Moroc...                        4   \n",
       "4  1 Krishnarajah G. Cost-effectiveness analysis ...                        1   \n",
       "\n",
       "    sim_pos   sim_neg  correct  \n",
       "0  0.609932  0.633598    False  \n",
       "1  0.748564  0.125579     True  \n",
       "2  0.277476  0.365389    False  \n",
       "3  0.316427  0.051429     True  \n",
       "4  0.451703  0.189826     True  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "242277bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.4157390201678429)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hn['sim_neg'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "833ee3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.4431712256025563)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hn['sim_pos'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fac4e71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>negative_index_in_group</th>\n",
       "      <th>sim_pos</th>\n",
       "      <th>sim_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>63760.000000</td>\n",
       "      <td>63760.000000</td>\n",
       "      <td>63760.000000</td>\n",
       "      <td>63760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60827.147114</td>\n",
       "      <td>4.601239</td>\n",
       "      <td>0.443171</td>\n",
       "      <td>0.415739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23756.762111</td>\n",
       "      <td>2.496681</td>\n",
       "      <td>0.166992</td>\n",
       "      <td>0.172019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19699.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.324485</td>\n",
       "      <td>-0.422133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40242.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.336305</td>\n",
       "      <td>0.305455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60815.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.454442</td>\n",
       "      <td>0.428050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>81290.250000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.562367</td>\n",
       "      <td>0.539422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>102128.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.957413</td>\n",
       "      <td>0.958487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            query_id  negative_index_in_group       sim_pos       sim_neg\n",
       "count   63760.000000             63760.000000  63760.000000  63760.000000\n",
       "mean    60827.147114                 4.601239      0.443171      0.415739\n",
       "std     23756.762111                 2.496681      0.166992      0.172019\n",
       "min     19699.000000                 1.000000     -0.324485     -0.422133\n",
       "25%     40242.750000                 2.000000      0.336305      0.305455\n",
       "50%     60815.000000                 4.000000      0.454442      0.428050\n",
       "75%     81290.250000                 7.000000      0.562367      0.539422\n",
       "max    102128.000000                10.000000      0.957413      0.958487"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hn.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aad4fe",
   "metadata": {},
   "source": [
    "## try better encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f418b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ceb70cd",
   "metadata": {},
   "source": [
    "# Instantiate towers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ec78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c7c34f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class QryTower(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class DocTower(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "qryTower = QryTower()\n",
    "docTower = DocTower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fcf579e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_to_embedding(words):\n",
    "    tokens = words.lower().split()\n",
    "    indices = [token_to_index.get(tok, 0) for tok in tokens]  # 0 for unknowns - get the value associated with the words\n",
    "\n",
    "    indices_tensor = torch.tensor(indices, dtype=torch.long, device=device) # converts the list indices into a PyTorch tensors\n",
    "\n",
    "    with torch.no_grad(): # This makes the code faster and uses less memory, because you're not training, just extracting embeddings.\n",
    "        embeds = embedding_layer(indices_tensor) # [num_tokens, embedding_dim]\n",
    "        return embeds.mean(dim=0) # average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "46a15c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vecs = []\n",
    "pos_vecs = []\n",
    "neg_vecs = []\n",
    "\n",
    "for _, row in df_hn.iterrows():\n",
    "    query_vecs.append(title_to_embedding(row[\"query\"]))\n",
    "    pos_vecs.append(title_to_embedding(row[\"positive_passage\"]))\n",
    "    neg_vecs.append(title_to_embedding(row[\"negative_passage\"]))\n",
    "\n",
    "# Stack into tensors: [N, D]\n",
    "query_vecs = torch.stack(query_vecs)\n",
    "pos_vecs = torch.stack(pos_vecs)\n",
    "neg_vecs = torch.stack(neg_vecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "673bca4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_vecs[12].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df76d2b9",
   "metadata": {},
   "source": [
    "## Initialise the model - Two neural nets (QryTower, DocTower) that learn to project those embeddings into a new space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4109437",
   "metadata": {},
   "outputs": [],
   "source": [
    "qryTower = QryTower().to(device) #Initialize and move models to the right device\n",
    "docTower = DocTower().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c591e1",
   "metadata": {},
   "source": [
    "## Pass embeddings through the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eafa0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qry = qryTower(query_vecs)   # [N, 1] \n",
    "pos = docTower(pos_vecs)     # [N, 1]\n",
    "neg = docTower(neg_vecs)     # [N, 1]\n",
    "\n",
    "# Cosine similarities along dim=1 (batch)\n",
    "dst_pos = F.cosine_similarity(qry, pos, dim=1)\n",
    "dst_neg = F.cosine_similarity(qry, neg, dim=1)\n",
    "\n",
    "dst_dif = dst_pos - dst_neg\n",
    "margin = 0.2\n",
    "loss = torch.clamp(margin - dst_dif, min=0).mean()\n",
    "\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbe717e",
   "metadata": {},
   "source": [
    "## define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c5d8cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    list(qryTower.parameters()) + list(docTower.parameters()), \n",
    "    lr=1e-3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d78be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3508\n"
     ]
    }
   ],
   "source": [
    "qryTower.train() # Puts both models into training mode\n",
    "docTower.train()\n",
    "\n",
    "for epoch in range(1):  # you can increase epochs\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, row in df_hn.iterrows():\n",
    "        query_vec = title_to_embedding(row[\"query\"]).unsqueeze(0).to(device)\n",
    "        pos_vec = title_to_embedding(row[\"positive_passage\"]).unsqueeze(0).to(device)\n",
    "        neg_vec = title_to_embedding(row[\"negative_passage\"]).unsqueeze(0).to(device)\n",
    "\n",
    "        qry = qryTower(query_vec)\n",
    "        pos = docTower(pos_vec)\n",
    "        neg = docTower(neg_vec)\n",
    "\n",
    "        dst_pos = F.cosine_similarity(qry, pos)\n",
    "        dst_neg = F.cosine_similarity(qry, neg)\n",
    "        margin = 0.2\n",
    "        loss = torch.clamp(margin - (dst_pos - dst_neg), min=0).mean() #ensures the loss is never negative\n",
    "\n",
    "        optimizer.zero_grad() # clears old gradients\n",
    "        loss.backward() # computes new gradients from the loss\n",
    "        optimizer.step() #updates model weights to reduce the loss\n",
    "\n",
    "        total_loss += loss.item() # Accumulate the scalar loss so you can report the average later\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(df_hn):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457af6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        query = title_to_embedding(row[\"query\"])\n",
    "        pos = title_to_embedding(row[\"positive_passage\"])\n",
    "        neg = title_to_embedding(row[\"negative_passage\"])\n",
    "        return query, pos, neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ee815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = TripletDataset(df_hn)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

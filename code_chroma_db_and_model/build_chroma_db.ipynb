{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "853538fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Make sure this notebook is running on the GPU\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from model import DocTower\n",
    "import chromadb\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b9fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58180712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Repo Hugging Face\n",
    "repo_id = \"nodozi/MLX_Week2\"\n",
    "\n",
    "# 1. Download embeddings\n",
    "embedding_path = hf_hub_download(\n",
    "    repo_id=repo_id,\n",
    "    filename=\"glove_embeddings.pt\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "\n",
    "embeddings = torch.load(embedding_path, map_location=device)  # [vocab_size, embedding_dim]\n",
    "\n",
    "# 2. Download vocab\n",
    "vocab_path = hf_hub_download(\n",
    "    repo_id=repo_id,\n",
    "    filename=\"glove_ids_to_words.csv\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96a0a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocabulary(csv_path):\n",
    "    word_to_idx = {}\n",
    "    with open(csv_path, mode='r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # 🟢 saute la première ligne\n",
    "        for row in reader:\n",
    "            if len(row) == 2:\n",
    "                idx, word = row\n",
    "                word_to_idx[word] = int(idx)\n",
    "    return word_to_idx\n",
    "\n",
    "\n",
    "token_to_index = load_vocabulary(vocab_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "944d73e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Embedding config\n",
    "embedding_dim = embeddings.shape[1]\n",
    "vocab_size = embeddings.shape[0]\n",
    "\n",
    "embedding_layer = nn.Embedding.from_pretrained(embeddings, freeze=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c96c9598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79704\n",
      "79704\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Results-Based Accountability® (also known as R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From Wikipedia, the free encyclopedia. A Reaga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sydney is the capital city of the Australian s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Install ceramic tile floor to match shower-A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Conversion disorder is a type of somatoform di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159403</th>\n",
       "      <td>A minimum of two credits of laboratory science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159404</th>\n",
       "      <td>1 The mitochondria of eukaryotes evolved from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159405</th>\n",
       "      <td>Raynaud's (say ray-NOHZ) phenomenon is a probl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159406</th>\n",
       "      <td>While kids feel like they’ve been grownups for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159407</th>\n",
       "      <td>Calculating Costs Per Inmate. According to the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159408 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 passages\n",
       "0       Results-Based Accountability® (also known as R...\n",
       "1       From Wikipedia, the free encyclopedia. A Reaga...\n",
       "2       Sydney is the capital city of the Australian s...\n",
       "3       1 Install ceramic tile floor to match shower-A...\n",
       "4       Conversion disorder is a type of somatoform di...\n",
       "...                                                   ...\n",
       "159403  A minimum of two credits of laboratory science...\n",
       "159404  1 The mitochondria of eukaryotes evolved from ...\n",
       "159405  Raynaud's (say ray-NOHZ) phenomenon is a probl...\n",
       "159406  While kids feel like they’ve been grownups for...\n",
       "159407  Calculating Costs Per Inmate. According to the...\n",
       "\n",
       "[159408 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the list of documents\n",
    "# Prepare the document dataset\n",
    "# Get the dataset from cocoritz\n",
    "# Combine the positive and negative passages into a single documents dataset\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "df_sn = load_dataset(\"cocoritzy/week_2_triplet_dataset_soft_negatives\")\n",
    "df_sn = df_sn[\"train\"].to_pandas()\n",
    "df_sn.head()\n",
    "\n",
    "# Create a list of documents from all values in the positive and negative columns \n",
    "print(len(df_sn['positive_passage'].tolist()))\n",
    "print(len(df_sn['negative_passage'].tolist()))\n",
    "all_passages = df_sn['positive_passage'].tolist() + df_sn['negative_passage'].tolist()\n",
    "df = pd.DataFrame({'passages': all_passages})\n",
    "df \n",
    "# print(all_passages[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9088664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, df, token_to_index, embedding_layer, device):\n",
    "        self.df = df\n",
    "        self.token_to_index = token_to_index\n",
    "        self.embedding_layer = embedding_layer\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding_dim = embedding_layer.embedding_dim\n",
    "        self.oov_embeddings = {}  # For storing fixed random vectors for OOV tokens\n",
    "\n",
    "        #self.query_max_len = max(len(text.lower().split()) for text in df[\"query\"])\n",
    "        #all_docs = df[\"positive_passage\"].tolist() + df[\"negative_passage\"].tolist()\n",
    "        self.doc_max_len = max(len(text.lower().split()) for text in df[\"passages\"])\n",
    "\n",
    "    def embed(self, token):\n",
    "        \"\"\"Return embedding for token: from vocab or generate fixed OOV vector.\"\"\"\n",
    "        if token in self.token_to_index:\n",
    "            idx = self.token_to_index[token]\n",
    "            return self.embedding_layer(torch.tensor(idx, device=self.device))\n",
    "        else:\n",
    "            if token not in self.oov_embeddings:\n",
    "                self.oov_embeddings[token] = torch.randn(self.embedding_dim, device=self.device) * 0.1\n",
    "            return self.oov_embeddings[token]\n",
    "    \n",
    "    def embed_text(self, text, max_len):\n",
    "        tokens = text.lower().split()\n",
    "        embedded_tokens = []\n",
    "\n",
    "        for tok in tokens[:max_len]:\n",
    "            emb = self.embed(tok)\n",
    "            embedded_tokens.append(emb)\n",
    "\n",
    "        true_len = len(embedded_tokens)\n",
    "\n",
    "        # Padding with vector at index 0\n",
    "        pad_len = max_len - true_len\n",
    "        if pad_len > 0:\n",
    "            pad_vec = self.embedding_layer(torch.tensor(0, device=self.device))  # index 0 used for padding\n",
    "            embedded_tokens.extend([pad_vec] * pad_len)\n",
    "\n",
    "        embedded = torch.stack(embedded_tokens)\n",
    "        return embedded, true_len\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        doc, d_len   = self.embed_text(row[\"passages\"], self.doc_max_len)\n",
    "\n",
    "        return doc,d_len\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Unpack everything from the batch\n",
    "    doc, d_len = zip(*batch)\n",
    "\n",
    "    # Stack the tensors and lengths\n",
    "    return (\n",
    "        torch.stack(doc),torch.tensor(d_len)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a49283",
   "metadata": {},
   "source": [
    "## calling our datagrame embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f5e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "triplet_dataset = TripletDataset(df, token_to_index, embedding_layer, device)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    triplet_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccaad08",
   "metadata": {},
   "source": [
    "## create the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd70edd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection already contains 0 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/1246 [02:04<1:55:04,  5.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m embeddings_np[j]\n\u001b[1;32m     43\u001b[0m     passage \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[i \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m128\u001b[39m \u001b[38;5;241m+\u001b[39m j][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassages\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mpassage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexisting_docs_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Update the count of existing documents\u001b[39;00m\n\u001b[1;32m     51\u001b[0m existing_docs_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m embeddings_np\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/code_mercredi/encoding_model/venv/lib/python3.10/site-packages/chromadb/api/models/Collection.py:89\u001b[0m, in \u001b[0;36mCollection.add\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Add embeddings to the data store.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    ids: The ids of the embeddings you wish to add\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m add_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_prepare_add_request(\n\u001b[1;32m     81\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m     82\u001b[0m     embeddings\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     uris\u001b[38;5;241m=\u001b[39muris,\n\u001b[1;32m     87\u001b[0m )\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadatas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43muris\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muris\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code_mercredi/encoding_model/venv/lib/python3.10/site-packages/chromadb/api/rust.py:402\u001b[0m, in \u001b[0;36mRustBindingsAPI._add\u001b[0;34m(self, ids, collection_id, embeddings, metadatas, documents, uris, tenant, database)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_add\u001b[39m(\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m     database: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m DEFAULT_DATABASE,\n\u001b[1;32m    391\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproduct_telemetry_client\u001b[38;5;241m.\u001b[39mcapture(\n\u001b[1;32m    393\u001b[0m         CollectionAddEvent(\n\u001b[1;32m    394\u001b[0m             collection_uuid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(collection_id),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m         )\n\u001b[1;32m    400\u001b[0m     )\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the complete statedict\n",
    "state_dict = torch.load(\"two_tower_model_GRU_padding.pt\", map_location=device)\n",
    "\n",
    "\n",
    "# Extract only the DocTower parameters\n",
    "doc_tower_state = state_dict['docTower']\n",
    "word_to_id = state_dict['token_to_index']\n",
    "\n",
    "model = DocTower()\n",
    "model.load_state_dict(doc_tower_state)\n",
    "model.eval()\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# Create or access a collection\n",
    "collection_name = 'marco_sn_documents'\n",
    "collection = client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "# Determine how many documents are already in the collection\n",
    "existing_docs_count = collection.count()\n",
    "print(f\"Collection already contains {existing_docs_count} documents\")\n",
    "\n",
    "# Iterate over the DataLoader and add documents to the collection\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "for i, (doc, d_len) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "    # Move the data to the GPU\n",
    "    doc = doc.to(device)\n",
    "    d_len = d_len.to(device)\n",
    "\n",
    "    # Get the embeddings\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(doc, d_len)\n",
    "\n",
    "    # Convert embeddings to numpy arrays\n",
    "    embeddings_np = embeddings.cpu().numpy()\n",
    "\n",
    "    # Add documents to the collection\n",
    "    for j in range(embeddings_np.shape[0]):\n",
    "        embedding = embeddings_np[j]\n",
    "        passage = df.iloc[i * 128 + j]['passages']\n",
    "        collection.add(\n",
    "            documents=[passage],\n",
    "            metadatas=[{\"index\": i * 128 + j}],\n",
    "            ids=[str(existing_docs_count + i * 128 + j)],\n",
    "            embeddings=[embedding]\n",
    "        )\n",
    "    # Update the count of existing documents\n",
    "    existing_docs_count += embeddings_np.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the documents\n",
    "def embed_docs(model, token_to_index, documents, batch_size, device, collection=None, start_id=0):\n",
    "\n",
    "    \"\"\"\n",
    "    Embed a list of texts using a pre-trained model.\n",
    "    \n",
    "    Args:\n",
    "        model: The pre-trained doc tower model to use for embedding.\n",
    "        documents: The list of texts to embed.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    total_documents = len(documents)\n",
    "    \n",
    "    # Create progress bar for the total number of batches\n",
    "    total_batches = (total_documents + batch_size - 1) // batch_size\n",
    "    progress_bar = tqdm(range(total_batches), desc=\"Processing batches\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, total_documents, batch_size):\n",
    "\n",
    "            # Get batch of data\n",
    "            batch_passages = documents[i:i + batch_size] \n",
    "\n",
    "            # Convert text to token ids using the model's vocab\n",
    "            batch_ids = []\n",
    "            batch_lengths = []\n",
    "            max_len = 201\n",
    "\n",
    "            for doc in batch_passages:\n",
    "                # Split into words and convert to ids\n",
    "                words = doc.split()\n",
    "                ids = [token_to_index.get(word, token_to_index.get('<unk>', 0)) for word in words]\n",
    "                batch_ids.append(ids)\n",
    "                batch_lengths.append(len(ids))\n",
    "                max_len = max(max_len, len(ids))\n",
    "            \n",
    "            # Pad sequences to max length\n",
    "            padded_ids = []\n",
    "            for ids in batch_ids:\n",
    "                padding = [0] * (max_len - len(ids))  # Assuming 0 is the padding token\n",
    "                padded_ids.append(ids + padding)\n",
    "            \n",
    "            # Convert to tensors\n",
    "            input_ids = torch.tensor(padded_ids, device=device).float() # GRU requires a float\n",
    "            lengths = torch.tensor(batch_lengths, device=device)\n",
    "\n",
    "            # Debug prints\n",
    "            print(f\"Input shape: {input_ids.shape}\")\n",
    "            print(f\"Lengths shape: {lengths.shape}\")\n",
    "        \n",
    "\n",
    "            doc_embeds = model(input_ids, lengths)\n",
    "            batch_embeddings = doc_embeds.cpu().numpy()\n",
    "            \n",
    "            batch_ids = [str(start_id + i + j) for j in range(len(batch_passages))]\n",
    "            \n",
    "            \n",
    "            print('Documents embedded. Storing to ChromaDB...')\n",
    "            # Add batch directly to ChromaDB collection\n",
    "            collection.add(\n",
    "                documents=batch_passages,\n",
    "                ids=batch_ids,\n",
    "                embeddings=batch_embeddings\n",
    "            )\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.update()\n",
    "            progress_bar.set_postfix({\"Processed\": f\"{i+batch_size}/{len(documents)} passages\"})\n",
    "\n",
    "    print('Documents embedded and stored in ChromaDB.')\n",
    "    return \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66536f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_chroma():\n",
    "        # Add batch directly to ChromaDB collection\n",
    "    collection.add(\n",
    "        documents=passages,# list\n",
    "        ids=ids, # list \n",
    "        embeddings=embeddings # list\n",
    "        )\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1117ba0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

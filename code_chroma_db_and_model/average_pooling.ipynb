{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b2d06c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from model import CBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebabe813",
   "metadata": {},
   "source": [
    "## retrieve the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3386c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model \n",
    "model_path = hf_hub_download(repo_id=\"cocoritzy/cbow-upvotes_model\", filename=\"cbow_model.pt\")\n",
    "\n",
    "# Retrieve checkpoint \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint = torch.load(model_path, map_location=device) #A checkpoint is a file that saves the state of your model (\n",
    "\n",
    "embedding_dim= checkpoint[\"embedding_dim\"]\n",
    "token_to_index = checkpoint[\"token_to_index\"]\n",
    "vocab_size = len(token_to_index)  # fill in actual size\n",
    "\n",
    "model = CBOW(voc=vocab_size, emb=embedding_dim)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "\n",
    "embedding_layer = model.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f10f720",
   "metadata": {},
   "source": [
    "## retreive datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2090b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "df_hn = load_dataset(\"cocoritzy/week_2_triplet_dataset_hard_negatives\")\n",
    "df_sn = load_dataset(\"cocoritzy/week_2_triplet_dataset_soft_negatives\")\n",
    "# dataset = load_dataset(\"cocoritzy/week_2_triplet_dataset_hard_negatives\", split=\"train[:10%]\") # 10% of the datab\n",
    "df_hn = df_hn[\"train\"].to_pandas()\n",
    "df_sn = df_sn[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6d470333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>positive_passage</th>\n",
       "      <th>negative_passage</th>\n",
       "      <th>negative_from_query_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19699</td>\n",
       "      <td>what is rba</td>\n",
       "      <td>Results-Based Accountability¬Æ (also known as R...</td>\n",
       "      <td>I finally found some real salary data for phys...</td>\n",
       "      <td>86595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19700</td>\n",
       "      <td>was ronald reagan a democrat</td>\n",
       "      <td>From Wikipedia, the free encyclopedia. A Reaga...</td>\n",
       "      <td>The Pacific Ocean lies to the east while the S...</td>\n",
       "      <td>66360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19701</td>\n",
       "      <td>how long do you need for sydney and surroundin...</td>\n",
       "      <td>Sydney is the capital city of the Australian s...</td>\n",
       "      <td>Probiotics are found in foods such as yogurt, ...</td>\n",
       "      <td>88507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19702</td>\n",
       "      <td>price to install tile in shower</td>\n",
       "      <td>1 Install ceramic tile floor to match shower-A...</td>\n",
       "      <td>Iodine is critical to thyroid health and funct...</td>\n",
       "      <td>87550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19703</td>\n",
       "      <td>why conversion observed in body</td>\n",
       "      <td>Conversion disorder is a type of somatoform di...</td>\n",
       "      <td>The answer to the question how much does it co...</td>\n",
       "      <td>61479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79699</th>\n",
       "      <td>102124</td>\n",
       "      <td>meaning of propagation</td>\n",
       "      <td>definition of propagation the act or action of...</td>\n",
       "      <td>A minimum of two credits of laboratory science...</td>\n",
       "      <td>21857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79700</th>\n",
       "      <td>102125</td>\n",
       "      <td>do you have to do a phd to be a clinical psych...</td>\n",
       "      <td>The goal you choose will determine your path. ...</td>\n",
       "      <td>1 The mitochondria of eukaryotes evolved from ...</td>\n",
       "      <td>28764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79701</th>\n",
       "      <td>102126</td>\n",
       "      <td>what wine goes with oysters</td>\n",
       "      <td>You may also enjoy these other types of wine w...</td>\n",
       "      <td>Raynaud's (say ray-NOHZ) phenomenon is a probl...</td>\n",
       "      <td>42284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79702</th>\n",
       "      <td>102127</td>\n",
       "      <td>what strengths does lithium come in</td>\n",
       "      <td>Lithium 150 mg. Lithium (Eskalith ¬Æ , Eskalith...</td>\n",
       "      <td>While kids feel like they‚Äôve been grownups for...</td>\n",
       "      <td>42891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79703</th>\n",
       "      <td>102128</td>\n",
       "      <td>what is polarity index definition</td>\n",
       "      <td>Polarity Index. Burdick &amp; Jackson solvents are...</td>\n",
       "      <td>Calculating Costs Per Inmate. According to the...</td>\n",
       "      <td>94401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79704 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       query_id                                              query  \\\n",
       "0         19699                                        what is rba   \n",
       "1         19700                       was ronald reagan a democrat   \n",
       "2         19701  how long do you need for sydney and surroundin...   \n",
       "3         19702                    price to install tile in shower   \n",
       "4         19703                    why conversion observed in body   \n",
       "...         ...                                                ...   \n",
       "79699    102124                             meaning of propagation   \n",
       "79700    102125  do you have to do a phd to be a clinical psych...   \n",
       "79701    102126                        what wine goes with oysters   \n",
       "79702    102127                what strengths does lithium come in   \n",
       "79703    102128                  what is polarity index definition   \n",
       "\n",
       "                                        positive_passage  \\\n",
       "0      Results-Based Accountability¬Æ (also known as R...   \n",
       "1      From Wikipedia, the free encyclopedia. A Reaga...   \n",
       "2      Sydney is the capital city of the Australian s...   \n",
       "3      1 Install ceramic tile floor to match shower-A...   \n",
       "4      Conversion disorder is a type of somatoform di...   \n",
       "...                                                  ...   \n",
       "79699  definition of propagation the act or action of...   \n",
       "79700  The goal you choose will determine your path. ...   \n",
       "79701  You may also enjoy these other types of wine w...   \n",
       "79702  Lithium 150 mg. Lithium (Eskalith ¬Æ , Eskalith...   \n",
       "79703  Polarity Index. Burdick & Jackson solvents are...   \n",
       "\n",
       "                                        negative_passage  \\\n",
       "0      I finally found some real salary data for phys...   \n",
       "1      The Pacific Ocean lies to the east while the S...   \n",
       "2      Probiotics are found in foods such as yogurt, ...   \n",
       "3      Iodine is critical to thyroid health and funct...   \n",
       "4      The answer to the question how much does it co...   \n",
       "...                                                  ...   \n",
       "79699  A minimum of two credits of laboratory science...   \n",
       "79700  1 The mitochondria of eukaryotes evolved from ...   \n",
       "79701  Raynaud's (say ray-NOHZ) phenomenon is a probl...   \n",
       "79702  While kids feel like they‚Äôve been grownups for...   \n",
       "79703  Calculating Costs Per Inmate. According to the...   \n",
       "\n",
       "       negative_from_query_id  \n",
       "0                       86595  \n",
       "1                       66360  \n",
       "2                       88507  \n",
       "3                       87550  \n",
       "4                       61479  \n",
       "...                       ...  \n",
       "79699                   21857  \n",
       "79700                   28764  \n",
       "79701                   42284  \n",
       "79702                   42891  \n",
       "79703                   94401  \n",
       "\n",
       "[79704 rows x 5 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0e67f8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79704 entries, 0 to 79703\n",
      "Data columns (total 5 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   query_id                79704 non-null  int64 \n",
      " 1   query                   79704 non-null  object\n",
      " 2   positive_passage        79704 non-null  object\n",
      " 3   negative_passage        79704 non-null  object\n",
      " 4   negative_from_query_id  79704 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3838a06c",
   "metadata": {},
   "source": [
    "## split the training and testing datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ce1e1bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 63763 entries, 5007 to 15795\n",
      "Data columns (total 5 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   query_id                63763 non-null  int64 \n",
      " 1   query                   63763 non-null  object\n",
      " 2   positive_passage        63763 non-null  object\n",
      " 3   negative_passage        63763 non-null  object\n",
      " 4   negative_from_query_id  63763 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sn, test_sn = train_test_split(\n",
    "    df_sn,\n",
    "    train_size=0.80,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_sn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b0e101",
   "metadata": {},
   "source": [
    "## count the max words in negative, p and query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0d6389fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "201\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "def count_max_words(column_name):\n",
    "    token_lists = train_sn[column_name].apply(lambda x: x.split())\n",
    "    word_counts = token_lists.apply(len)\n",
    "    return print(word_counts.max())\n",
    "\n",
    "count_max_words(\"negative_passage\")\n",
    "count_max_words(\"positive_passage\")\n",
    "count_max_words(\"query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "86220dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TripletDataset(Dataset): #Defines a new dataset class that returns triplets: query, positive doc, negative doc.\n",
    "\n",
    "    def __init__(self, df, token_to_index, embedding_layer, device):\n",
    "        self.df = df\n",
    "        self.token_to_index = token_to_index\n",
    "        self.embedding_layer = embedding_layer\n",
    "        self.device = device\n",
    "\n",
    "        self.query_max_len = max(len(text.lower().split()) for text in df[\"query\"]) #Calculates the maximum length of the query text in the dataset.\n",
    "        all_docs = df[\"positive_passage\"].tolist() + df[\"negative_passage\"].tolist() # Combines all documents (positive and negative) into one list.\n",
    "        self.doc_max_len = max(len(text.lower().split()) for text in all_docs)\n",
    "        \n",
    "    \n",
    "    def embed_and_pad(self, text, max_len):\n",
    "        tokens = text.lower().split()\n",
    "        indices = [self.token_to_index.get(tok, 0) for tok in tokens[:max_len]]  # Converts the list of indices into a PyTorch tensor and moves it to the correct device (CPU/GPU).\n",
    "        indices += [0] * (max_len - len(indices))  # pad with 0s\n",
    "        indices_tensor = torch.tensor(indices, dtype=torch.long, device=self.device) #Passes the tensor through the embedding layer.  \n",
    "        embedded = self.embedding_layer(indices_tensor)  # [max_len, embedding_dim]\n",
    "\n",
    "        return embedded\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        \n",
    "        query = self.embed_and_pad(row[\"query\"], self.query_max_len)\n",
    "        pos   = self.embed_and_pad(row[\"positive_passage\"], self.doc_max_len)\n",
    "        neg   = self.embed_and_pad(row[\"negative_passage\"], self.doc_max_len)\n",
    "    \n",
    "\n",
    "        return query, pos, neg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "877ac981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch shapes:\n",
      "Query batch: torch.Size([128, 26, 100])\n",
      "Pos batch: torch.Size([128, 201, 100])\n",
      "Neg batch: torch.Size([128, 201, 100])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "triplet_dataset = TripletDataset(train_sn, token_to_index, embedding_layer, device)\n",
    "dataloader = DataLoader(triplet_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "for query, pos, neg in dataloader:\n",
    "    print(\"\\nBatch shapes:\")\n",
    "    print(\"Query batch:\", query.shape)\n",
    "    print(\"Pos batch:\", pos.shape)\n",
    "    print(\"Neg batch:\", neg.shape)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a08860",
   "metadata": {},
   "source": [
    "## similarity test after embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0a33b0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Similarit√© cosinus entre deux requ√™tes identiques : 1.0000\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# R√©cup√®re un batch\n",
    "for query_batch, _, _ in dataloader:\n",
    "    # Prends deux vecteurs identiques du batch\n",
    "    q1 = query_batch[0]  # (seq_len, emb_dim)\n",
    "    q2 = query_batch[0]  # m√™me vecteur que q1\n",
    "\n",
    "    # Moyenne des embeddings pour obtenir un vecteur global de la phrase\n",
    "    q1_vec = q1.mean(dim=0).unsqueeze(0)  # (1, emb_dim)\n",
    "    q2_vec = q2.mean(dim=0).unsqueeze(0)\n",
    "\n",
    "    # Similarit√© cosinus\n",
    "    similarity = F.cosine_similarity(q1_vec, q2_vec)\n",
    "    print(f\"‚úÖ Similarit√© cosinus entre deux requ√™tes identiques : {similarity.item():.4f}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df6605",
   "metadata": {},
   "source": [
    "## create the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4eb9b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# # from model_average import QryTower, DocTower\n",
    "\n",
    "# class QryTower(nn.Module):\n",
    "#     def forward(self, x):\n",
    "#         return x.mean(dim=1)  # [batch_size, embedding_dim]\n",
    "\n",
    "# class DocTower(nn.Module):\n",
    "#     def forward(self, x):\n",
    "#         return x.mean(dim=1)  # [batch_size, embedding_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e9ff6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class QryTower(nn.Module):\n",
    "    def __init__(self, embedding_dim=100, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x):  # x : [batch_size, seq_len, emb_dim]\n",
    "        _, hidden = self.rnn(x)\n",
    "        return hidden.squeeze(0)  # [batch_size, hidden_dim]\n",
    "\n",
    "class DocTower(nn.Module):\n",
    "    def __init__(self, embedding_dim=100, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x):  # x : [batch_size, seq_len, emb_dim]\n",
    "        _, hidden = self.rnn(x)\n",
    "        return hidden.squeeze(0)  # [batch_size, hidden_dim]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de56357",
   "metadata": {},
   "source": [
    "##¬†model initialisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ccfa9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qryTower = QryTower().to(device)\n",
    "docTower = DocTower().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c96ca343",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "49057316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Combine parameters from both towers\n",
    "params = list(qryTower.parameters()) + list(docTower.parameters())\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = optim.Adam(params, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9456fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5fa3e25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 0.4278\n",
      "Epoch 2, Avg Loss: 0.2585\n",
      "Epoch 3, Avg Loss: 0.2177\n",
      "Epoch 4, Avg Loss: 0.1813\n",
      "Epoch 5, Avg Loss: 0.1563\n",
      "Epoch 6, Avg Loss: 0.1387\n",
      "Epoch 7, Avg Loss: 0.1262\n",
      "Epoch 8, Avg Loss: 0.1160\n",
      "Epoch 9, Avg Loss: 0.1083\n",
      "Epoch 10, Avg Loss: 0.1012\n",
      "Epoch 11, Avg Loss: 0.0950\n",
      "Epoch 12, Avg Loss: 0.0901\n",
      "Epoch 13, Avg Loss: 0.0844\n",
      "Epoch 14, Avg Loss: 0.0802\n",
      "Epoch 15, Avg Loss: 0.0762\n",
      "Epoch 16, Avg Loss: 0.0725\n",
      "Epoch 17, Avg Loss: 0.0688\n",
      "Epoch 18, Avg Loss: 0.0664\n",
      "Epoch 19, Avg Loss: 0.0640\n",
      "Epoch 20, Avg Loss: 0.0604\n"
     ]
    }
   ],
   "source": [
    "qryTower.train()\n",
    "docTower.train()\n",
    "\n",
    "margin = 0.5  # marge pour la triplet loss\n",
    "\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "\n",
    "    for qry, pos, neg in dataloader:\n",
    "        qry, pos, neg = qry.to(device), pos.to(device), neg.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        qry_vec = qryTower(qry)  # [batch, emb_dim]\n",
    "        pos_vec = docTower(pos)\n",
    "        neg_vec = docTower(neg)\n",
    "\n",
    "        # 2. Cosine similarity\n",
    "        sim_pos = torch.nn.functional.cosine_similarity(qry_vec, pos_vec, dim=1)  # [batch]\n",
    "        sim_neg = torch.nn.functional.cosine_similarity(qry_vec, neg_vec, dim=1)\n",
    "\n",
    "        # 3. Triplet loss : max(0, margin - (sim_pos - sim_neg))\n",
    "        loss = torch.relu(margin - (sim_pos - sim_neg)).mean()\n",
    "\n",
    "        # 4. Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Avg Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8c985996",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TripletDataset(test_sn, token_to_index, embedding_layer, device)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "14e16934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Accuracy sur le set de test : 86.46%\n"
     ]
    }
   ],
   "source": [
    "qryTower.eval()\n",
    "docTower.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for qry, pos, neg in test_loader:\n",
    "        qry, pos, neg = qry.to(device), pos.to(device), neg.to(device)\n",
    "\n",
    "        qry_vec = qryTower(qry)\n",
    "        pos_vec = docTower(pos)\n",
    "        neg_vec = docTower(neg)\n",
    "\n",
    "        sim_pos = torch.nn.functional.cosine_similarity(qry_vec, pos_vec, dim=1)\n",
    "        sim_neg = torch.nn.functional.cosine_similarity(qry_vec, neg_vec, dim=1)\n",
    "\n",
    "        # compte si le mod√®le pr√©f√®re le doc positif\n",
    "        correct += (sim_pos > sim_neg).sum().item()\n",
    "        total += qry.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"‚úÖ Accuracy sur le set de test : {accuracy:.2%}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7290babe",
   "metadata": {},
   "source": [
    "## save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a8547314",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"qryTower\": qryTower.state_dict(),\n",
    "    \"docTower\": docTower.state_dict(),\n",
    "    \"token_to_index\": token_to_index\n",
    "}, \"two_tower_model_GRU.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "050146f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query = \"how to start learning deep learning\"\n",
    "my_passage = \"how to start learning deep learning\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "03135d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Similarit√© query-passage : 0.4976\n"
     ]
    }
   ],
   "source": [
    "qryTower.eval()\n",
    "docTower.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Tokenise et embed\n",
    "    qry_tensor = triplet_dataset.embed_and_pad(my_query, triplet_dataset.query_max_len).unsqueeze(0)\n",
    "    doc_tensor = triplet_dataset.embed_and_pad(my_passage, triplet_dataset.doc_max_len).unsqueeze(0)\n",
    "\n",
    "    # Encode avec les deux tours\n",
    "    qry_vec = qryTower(qry_tensor)\n",
    "    doc_vec = docTower(doc_tensor)\n",
    "\n",
    "    # Calcule la similarit√©\n",
    "    similarity = torch.nn.functional.cosine_similarity(qry_vec, doc_vec, dim=1)  # batch=1 ‚Üí r√©sultat = [1]\n",
    "    print(f\"\\nüîç Similarit√© query-passage : {similarity.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cb08a9",
   "metadata": {},
   "source": [
    "## same words, same tower, same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "233e3ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Similarit√© entre deux encodages identiques : 1.0000001192092896\n"
     ]
    }
   ],
   "source": [
    "query = \"hello world\"\n",
    "tensor1 = triplet_dataset.embed_and_pad(query, triplet_dataset.query_max_len).unsqueeze(0)\n",
    "tensor2 = triplet_dataset.embed_and_pad(query, triplet_dataset.query_max_len).unsqueeze(0)\n",
    "\n",
    "vec1 = qryTower(tensor1)\n",
    "vec2 = qryTower(tensor2)\n",
    "\n",
    "sim = torch.nn.functional.cosine_similarity(vec1, vec2, dim=1)\n",
    "print(\"üîÅ Similarit√© entre deux encodages identiques :\", sim.item())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

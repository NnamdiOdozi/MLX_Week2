{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2d06c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code_mercredi/encoding_model/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from model import CBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebabe813",
   "metadata": {},
   "source": [
    "## retrieve the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "243c1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Repo Hugging Face\n",
    "repo_id = \"nodozi/MLX_Week2\"\n",
    "\n",
    "# 1. Download embeddings\n",
    "embedding_path = hf_hub_download(\n",
    "    repo_id=repo_id,\n",
    "    filename=\"glove_embeddings.pt\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "\n",
    "embeddings = torch.load(embedding_path, map_location=device)  # [vocab_size, embedding_dim]\n",
    "\n",
    "# 2. Download vocab\n",
    "vocab_path = hf_hub_download(\n",
    "    repo_id=repo_id,\n",
    "    filename=\"glove_ids_to_words.csv\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b8234bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Token_ID', 'Word']\n",
      "['1', 'the']\n",
      "['2', ',']\n",
      "['3', '.']\n",
      "['4', 'of']\n"
     ]
    }
   ],
   "source": [
    "# Ouvre le fichier et affiche les 5 premi√®res lignes\n",
    "with open(vocab_path, mode='r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, row in enumerate(reader):\n",
    "        print(row)\n",
    "        if i == 4:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f12b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocabulary(csv_path):\n",
    "    word_to_idx = {}\n",
    "    with open(csv_path, mode='r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # üü¢ saute la premi√®re ligne\n",
    "        for row in reader:\n",
    "            if len(row) == 2:\n",
    "                idx, word = row\n",
    "                word_to_idx[word] = int(idx)\n",
    "    return word_to_idx\n",
    "\n",
    "\n",
    "token_to_index = load_vocabulary(vocab_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3fdf00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Le token '<pad>' n‚Äôest pas dans le vocabulaire.\n",
      "‚ùå Le token '<unk>' n‚Äôest pas dans le vocabulaire.\n",
      "‚ùå Le token 'PAD' n‚Äôest pas dans le vocabulaire.\n",
      "‚ùå Le token 'UNK' n‚Äôest pas dans le vocabulaire.\n",
      "‚ùå Le token '[PAD]' n‚Äôest pas dans le vocabulaire.\n",
      "‚ùå Le token '[UNK]' n‚Äôest pas dans le vocabulaire.\n"
     ]
    }
   ],
   "source": [
    "for token in [\"<pad>\", \"<unk>\", \"PAD\", \"UNK\", \"[PAD]\", \"[UNK]\"]:\n",
    "    if token in token_to_index:\n",
    "        print(f\"‚úÖ Le token sp√©cial '{token}' existe avec l‚Äôindex : {token_to_index[token]}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Le token '{token}' n‚Äôest pas dans le vocabulaire.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "603accf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Embedding config\n",
    "embedding_dim = embeddings.shape[1]\n",
    "vocab_size = embeddings.shape[0]\n",
    "\n",
    "embedding_layer = nn.Embedding.from_pretrained(embeddings, freeze=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f10f720",
   "metadata": {},
   "source": [
    "## retreive datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2090b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "df_hn = load_dataset(\"cocoritzy/week_2_triplet_dataset_hard_negatives\")\n",
    "df_sn = load_dataset(\"cocoritzy/week_2_triplet_dataset_soft_negatives\")\n",
    "# dataset = load_dataset(\"cocoritzy/week_2_triplet_dataset_hard_negatives\", split=\"train[:10%]\") # 10% of the datab\n",
    "df_hn = df_hn[\"train\"].to_pandas()\n",
    "df_sn = df_sn[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d470333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>positive_passage</th>\n",
       "      <th>negative_passage</th>\n",
       "      <th>negative_from_query_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19699</td>\n",
       "      <td>what is rba</td>\n",
       "      <td>Results-Based Accountability¬Æ (also known as R...</td>\n",
       "      <td>I finally found some real salary data for phys...</td>\n",
       "      <td>86595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19700</td>\n",
       "      <td>was ronald reagan a democrat</td>\n",
       "      <td>From Wikipedia, the free encyclopedia. A Reaga...</td>\n",
       "      <td>The Pacific Ocean lies to the east while the S...</td>\n",
       "      <td>66360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19701</td>\n",
       "      <td>how long do you need for sydney and surroundin...</td>\n",
       "      <td>Sydney is the capital city of the Australian s...</td>\n",
       "      <td>Probiotics are found in foods such as yogurt, ...</td>\n",
       "      <td>88507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19702</td>\n",
       "      <td>price to install tile in shower</td>\n",
       "      <td>1 Install ceramic tile floor to match shower-A...</td>\n",
       "      <td>Iodine is critical to thyroid health and funct...</td>\n",
       "      <td>87550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19703</td>\n",
       "      <td>why conversion observed in body</td>\n",
       "      <td>Conversion disorder is a type of somatoform di...</td>\n",
       "      <td>The answer to the question how much does it co...</td>\n",
       "      <td>61479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79699</th>\n",
       "      <td>102124</td>\n",
       "      <td>meaning of propagation</td>\n",
       "      <td>definition of propagation the act or action of...</td>\n",
       "      <td>A minimum of two credits of laboratory science...</td>\n",
       "      <td>21857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79700</th>\n",
       "      <td>102125</td>\n",
       "      <td>do you have to do a phd to be a clinical psych...</td>\n",
       "      <td>The goal you choose will determine your path. ...</td>\n",
       "      <td>1 The mitochondria of eukaryotes evolved from ...</td>\n",
       "      <td>28764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79701</th>\n",
       "      <td>102126</td>\n",
       "      <td>what wine goes with oysters</td>\n",
       "      <td>You may also enjoy these other types of wine w...</td>\n",
       "      <td>Raynaud's (say ray-NOHZ) phenomenon is a probl...</td>\n",
       "      <td>42284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79702</th>\n",
       "      <td>102127</td>\n",
       "      <td>what strengths does lithium come in</td>\n",
       "      <td>Lithium 150 mg. Lithium (Eskalith ¬Æ , Eskalith...</td>\n",
       "      <td>While kids feel like they‚Äôve been grownups for...</td>\n",
       "      <td>42891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79703</th>\n",
       "      <td>102128</td>\n",
       "      <td>what is polarity index definition</td>\n",
       "      <td>Polarity Index. Burdick &amp; Jackson solvents are...</td>\n",
       "      <td>Calculating Costs Per Inmate. According to the...</td>\n",
       "      <td>94401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79704 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       query_id                                              query  \\\n",
       "0         19699                                        what is rba   \n",
       "1         19700                       was ronald reagan a democrat   \n",
       "2         19701  how long do you need for sydney and surroundin...   \n",
       "3         19702                    price to install tile in shower   \n",
       "4         19703                    why conversion observed in body   \n",
       "...         ...                                                ...   \n",
       "79699    102124                             meaning of propagation   \n",
       "79700    102125  do you have to do a phd to be a clinical psych...   \n",
       "79701    102126                        what wine goes with oysters   \n",
       "79702    102127                what strengths does lithium come in   \n",
       "79703    102128                  what is polarity index definition   \n",
       "\n",
       "                                        positive_passage  \\\n",
       "0      Results-Based Accountability¬Æ (also known as R...   \n",
       "1      From Wikipedia, the free encyclopedia. A Reaga...   \n",
       "2      Sydney is the capital city of the Australian s...   \n",
       "3      1 Install ceramic tile floor to match shower-A...   \n",
       "4      Conversion disorder is a type of somatoform di...   \n",
       "...                                                  ...   \n",
       "79699  definition of propagation the act or action of...   \n",
       "79700  The goal you choose will determine your path. ...   \n",
       "79701  You may also enjoy these other types of wine w...   \n",
       "79702  Lithium 150 mg. Lithium (Eskalith ¬Æ , Eskalith...   \n",
       "79703  Polarity Index. Burdick & Jackson solvents are...   \n",
       "\n",
       "                                        negative_passage  \\\n",
       "0      I finally found some real salary data for phys...   \n",
       "1      The Pacific Ocean lies to the east while the S...   \n",
       "2      Probiotics are found in foods such as yogurt, ...   \n",
       "3      Iodine is critical to thyroid health and funct...   \n",
       "4      The answer to the question how much does it co...   \n",
       "...                                                  ...   \n",
       "79699  A minimum of two credits of laboratory science...   \n",
       "79700  1 The mitochondria of eukaryotes evolved from ...   \n",
       "79701  Raynaud's (say ray-NOHZ) phenomenon is a probl...   \n",
       "79702  While kids feel like they‚Äôve been grownups for...   \n",
       "79703  Calculating Costs Per Inmate. According to the...   \n",
       "\n",
       "       negative_from_query_id  \n",
       "0                       86595  \n",
       "1                       66360  \n",
       "2                       88507  \n",
       "3                       87550  \n",
       "4                       61479  \n",
       "...                       ...  \n",
       "79699                   21857  \n",
       "79700                   28764  \n",
       "79701                   42284  \n",
       "79702                   42891  \n",
       "79703                   94401  \n",
       "\n",
       "[79704 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e67f8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79704 entries, 0 to 79703\n",
      "Data columns (total 5 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   query_id                79704 non-null  int64 \n",
      " 1   query                   79704 non-null  object\n",
      " 2   positive_passage        79704 non-null  object\n",
      " 3   negative_passage        79704 non-null  object\n",
      " 4   negative_from_query_id  79704 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3838a06c",
   "metadata": {},
   "source": [
    "## split the training and testing datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce1e1bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 63763 entries, 5007 to 15795\n",
      "Data columns (total 5 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   query_id                63763 non-null  int64 \n",
      " 1   query                   63763 non-null  object\n",
      " 2   positive_passage        63763 non-null  object\n",
      " 3   negative_passage        63763 non-null  object\n",
      " 4   negative_from_query_id  63763 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sn, test_sn = train_test_split(\n",
    "    df_sn,\n",
    "    train_size=0.80,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_sn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b0e101",
   "metadata": {},
   "source": [
    "## count the max words in negative, p and query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d6389fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "201\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "def count_max_words(column_name):\n",
    "    token_lists = train_sn[column_name].apply(lambda x: x.split())\n",
    "    word_counts = token_lists.apply(len)\n",
    "    return print(word_counts.max())\n",
    "\n",
    "count_max_words(\"negative_passage\")\n",
    "count_max_words(\"positive_passage\")\n",
    "count_max_words(\"query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86220dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, df, token_to_index, embedding_layer, device):\n",
    "        self.df = df\n",
    "        self.token_to_index = token_to_index\n",
    "        self.embedding_layer = embedding_layer\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding_dim = embedding_layer.embedding_dim\n",
    "        self.oov_embeddings = {}  # For storing fixed random vectors for OOV tokens\n",
    "\n",
    "        self.query_max_len = max(len(text.lower().split()) for text in df[\"query\"])\n",
    "        all_docs = df[\"positive_passage\"].tolist() + df[\"negative_passage\"].tolist()\n",
    "        self.doc_max_len = max(len(text.lower().split()) for text in all_docs)\n",
    "\n",
    "    def embed(self, token):\n",
    "        \"\"\"Return embedding for token: from vocab or generate fixed OOV vector.\"\"\"\n",
    "        if token in self.token_to_index:\n",
    "            idx = self.token_to_index[token]\n",
    "            return self.embedding_layer(torch.tensor(idx, device=self.device))\n",
    "        else:\n",
    "            if token not in self.oov_embeddings:\n",
    "                self.oov_embeddings[token] = torch.randn(self.embedding_dim, device=self.device) * 0.1\n",
    "            return self.oov_embeddings[token]\n",
    "    \n",
    "    def embed_text(self, text, max_len):\n",
    "        tokens = text.lower().split()\n",
    "        embedded_tokens = []\n",
    "\n",
    "        for tok in tokens[:max_len]:\n",
    "            emb = self.embed(tok)\n",
    "            embedded_tokens.append(emb)\n",
    "\n",
    "        true_len = len(embedded_tokens)\n",
    "\n",
    "        # Padding with vector at index 0\n",
    "        pad_len = max_len - true_len\n",
    "        if pad_len > 0:\n",
    "            pad_vec = self.embedding_layer(torch.tensor(0, device=self.device))  # index 0 used for padding\n",
    "            embedded_tokens.extend([pad_vec] * pad_len)\n",
    "\n",
    "        embedded = torch.stack(embedded_tokens)\n",
    "        return embedded, true_len\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        query, q_len = self.embed_text(row[\"query\"], self.query_max_len)\n",
    "        pos, p_len   = self.embed_text(row[\"positive_passage\"], self.doc_max_len)\n",
    "        neg, n_len   = self.embed_text(row[\"negative_passage\"], self.doc_max_len)\n",
    "\n",
    "        return query, q_len, pos, p_len, neg, n_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8696264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Unpack everything from the batch\n",
    "    queries, q_lens, pos, p_lens, neg, n_lens = zip(*batch)\n",
    "\n",
    "    # Stack the tensors and lengths\n",
    "    return (\n",
    "        torch.stack(queries), torch.tensor(q_lens),\n",
    "        torch.stack(pos),     torch.tensor(p_lens),\n",
    "        torch.stack(neg),     torch.tensor(n_lens)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "877ac981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "triplet_dataset = TripletDataset(train_sn, token_to_index, embedding_layer, device)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    triplet_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "\n",
    "# for query, pos, neg in dataloader:\n",
    "#     print(\"\\nBatch shapes:\")\n",
    "#     print(\"Query batch:\", query.shape)\n",
    "#     print(\"Pos batch:\", pos.shape)\n",
    "#     print(\"Neg batch:\", neg.shape)\n",
    "#     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df6605",
   "metadata": {},
   "source": [
    "## create the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eb9b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# # from model_average import QryTower, DocTower\n",
    "\n",
    "# class QryTower(nn.Module):\n",
    "#     def forward(self, x):\n",
    "#         return x.mean(dim=1)  # [batch_size, embedding_dim]\n",
    "\n",
    "# class DocTower(nn.Module):\n",
    "#     def forward(self, x):\n",
    "#         return x.mean(dim=1)  # [batch_size, embedding_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9ff6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class QryTower(nn.Module):\n",
    "    def __init__(self, embedding_dim=100, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # 1. Sort by descending length\n",
    "        lengths, sort_idx = lengths.sort(descending=True)\n",
    "        x = x[sort_idx]\n",
    "\n",
    "        # 2. Pack\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True)\n",
    "\n",
    "        # 3. GRU\n",
    "        _, hidden = self.rnn(packed)  # hidden: [1, batch_size, hidden_dim]\n",
    "\n",
    "        # 4. Unsort\n",
    "        _, unsort_idx = sort_idx.sort()\n",
    "        hidden = hidden.squeeze(0)[unsort_idx]  # [batch_size, hidden_dim]\n",
    "\n",
    "        return hidden\n",
    "\n",
    "class DocTower(nn.Module):\n",
    "    def __init__(self, embedding_dim=100, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # 1. Sort by descending length\n",
    "        lengths, sort_idx = lengths.sort(descending=True)\n",
    "        x = x[sort_idx]\n",
    "\n",
    "        # 2. Pack\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True)\n",
    "\n",
    "        # 3. GRU\n",
    "        _, hidden = self.rnn(packed)  # hidden: [1, batch_size, hidden_dim]\n",
    "\n",
    "        # 4. Unsort\n",
    "        _, unsort_idx = sort_idx.sort()\n",
    "        hidden = hidden.squeeze(0)[unsort_idx]  # [batch_size, hidden_dim]\n",
    "\n",
    "        return hidden\n",
    "\n",
    "# class QryTower(nn.Module):\n",
    "#     def __init__(self, embedding_dim=100, hidden_dim=64):\n",
    "#         super().__init__()\n",
    "#         self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "#     def forward(self, x):  # x : [batch_size, seq_len, emb_dim]\n",
    "#         _, hidden = self.rnn(x)\n",
    "#         return hidden.squeeze(0)  # [batch_size, hidden_dim]\n",
    "\n",
    "# class DocTower(nn.Module):\n",
    "#     def __init__(self, embedding_dim=100, hidden_dim=64):\n",
    "#         super().__init__()\n",
    "#         self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "#     def forward(self, x):  # x : [batch_size, seq_len, emb_dim]\n",
    "#         _, hidden = self.rnn(x)\n",
    "#         return hidden.squeeze(0)  # [batch_size, hidden_dim]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de56357",
   "metadata": {},
   "source": [
    "##¬†model initialisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccfa9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qryTower = QryTower().to(device)\n",
    "docTower = DocTower().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c96ca343",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49057316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Combine parameters from both towers\n",
    "params = list(qryTower.parameters()) + list(docTower.parameters())\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = optim.Adam(params, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9456fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fa3e25a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m      7\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m qry, q_len, pos, p_len, neg, n_len \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# Move to device\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         qry, q_len \u001b[38;5;241m=\u001b[39m qry\u001b[38;5;241m.\u001b[39mto(device), q_len\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m         pos, p_len \u001b[38;5;241m=\u001b[39m pos\u001b[38;5;241m.\u001b[39mto(device), p_len\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/code_mercredi/encoding_model/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/code_mercredi/encoding_model/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/code_mercredi/encoding_model/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/code_mercredi/encoding_model/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[12], line 55\u001b[0m, in \u001b[0;36mTripletDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     52\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[1;32m     54\u001b[0m query, q_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_text(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_max_len)\n\u001b[0;32m---> 55\u001b[0m pos, p_len   \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpositive_passage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc_max_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m neg, n_len   \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_text(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative_passage\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_max_len)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query, q_len, pos, p_len, neg, n_len\n",
      "Cell \u001b[0;32mIn[12], line 33\u001b[0m, in \u001b[0;36mTripletDataset.embed_text\u001b[0;34m(self, text, max_len)\u001b[0m\n\u001b[1;32m     30\u001b[0m embedded_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m tokens[:max_len]:\n\u001b[0;32m---> 33\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     embedded_tokens\u001b[38;5;241m.\u001b[39mappend(emb)\n\u001b[1;32m     36\u001b[0m true_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(embedded_tokens)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "qryTower.train()\n",
    "docTower.train()\n",
    "\n",
    "margin = 0.5  # Triplet loss margin\n",
    "\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "\n",
    "    for qry, q_len, pos, p_len, neg, n_len in dataloader:\n",
    "        # Move to device\n",
    "        qry, q_len = qry.to(device), q_len.to(device)\n",
    "        pos, p_len = pos.to(device), p_len.to(device)\n",
    "        neg, n_len = neg.to(device), n_len.to(device)\n",
    "\n",
    "        # 1. Forward pass using RNN with packed sequences\n",
    "        qry_vec = qryTower(qry, q_len)  # [batch_size, hidden_dim]\n",
    "        pos_vec = docTower(pos, p_len)\n",
    "        neg_vec = docTower(neg, n_len)\n",
    "\n",
    "        # 2. Cosine similarity\n",
    "        sim_pos = torch.nn.functional.cosine_similarity(qry_vec, pos_vec, dim=1)\n",
    "        sim_neg = torch.nn.functional.cosine_similarity(qry_vec, neg_vec, dim=1)\n",
    "\n",
    "        # 3. Triplet loss\n",
    "        loss = torch.relu(margin - (sim_pos - sim_neg)).mean()\n",
    "\n",
    "        # 4. Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Avg Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c985996",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TripletDataset(test_sn, token_to_index, embedding_layer, device)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e16934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Accuracy sur le set de test : 96.01%\n"
     ]
    }
   ],
   "source": [
    "qryTower.eval()\n",
    "docTower.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for qry, q_len, pos, p_len, neg, n_len in dataloader:\n",
    "        # Move to device\n",
    "        qry, q_len = qry.to(device), q_len.to(device)\n",
    "        pos, p_len = pos.to(device), p_len.to(device)\n",
    "        neg, n_len = neg.to(device), n_len.to(device)\n",
    "\n",
    "        # 1. Forward pass using RNN with packed sequences\n",
    "        qry_vec = qryTower(qry, q_len)  # [batch_size, hidden_dim]\n",
    "        pos_vec = docTower(pos, p_len)\n",
    "        neg_vec = docTower(neg, n_len)\n",
    "\n",
    "        sim_pos = torch.nn.functional.cosine_similarity(qry_vec, pos_vec, dim=1)\n",
    "        sim_neg = torch.nn.functional.cosine_similarity(qry_vec, neg_vec, dim=1)\n",
    "\n",
    "        # compte si le mod√®le pr√©f√®re le doc positif\n",
    "        correct += (sim_pos > sim_neg).sum().item()\n",
    "        total += qry.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"‚úÖ Accuracy sur le set de test : {accuracy:.2%}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7290babe",
   "metadata": {},
   "source": [
    "## save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8547314",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"qryTower\": qryTower.state_dict(),\n",
    "    \"docTower\": docTower.state_dict(),\n",
    "    \"token_to_index\": token_to_index\n",
    "}, \"two_tower_model_GRU_padding_128.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050146f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query = \"what is rba\"\n",
    "my_passage = \"rba is how do you train  learning deep learning\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03135d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Similarit√© query-passage : 0.4412\n"
     ]
    }
   ],
   "source": [
    "qryTower.eval()\n",
    "docTower.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Tokenise et embed + get lengths\n",
    "    qry_tensor, qry_len = triplet_dataset.embed_text(my_query, triplet_dataset.query_max_len)\n",
    "    doc_tensor, doc_len = triplet_dataset.embed_text(my_passage, triplet_dataset.doc_max_len)\n",
    "\n",
    "    # Add batch dimension\n",
    "    qry_tensor = qry_tensor.unsqueeze(0)  # [1, seq_len, emb_dim]\n",
    "    doc_tensor = doc_tensor.unsqueeze(0)\n",
    "    qry_len = torch.tensor([qry_len])\n",
    "    doc_len = torch.tensor([doc_len])\n",
    "\n",
    "    # Move to device\n",
    "    qry_tensor, qry_len = qry_tensor.to(device), qry_len.to(device)\n",
    "    doc_tensor, doc_len = doc_tensor.to(device), doc_len.to(device)\n",
    "\n",
    "    # Encode with towers (using packed sequences)\n",
    "    qry_vec = qryTower(qry_tensor, qry_len)  # [1, hidden_dim]\n",
    "    doc_vec = docTower(doc_tensor, doc_len)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = torch.nn.functional.cosine_similarity(qry_vec, doc_vec, dim=1)\n",
    "    print(f\"\\nüîç Similarit√© query-passage : {similarity.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cb08a9",
   "metadata": {},
   "source": [
    "## same words, same tower, same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e3ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Similarit√© entre deux encodages identiques : 1.0\n"
     ]
    }
   ],
   "source": [
    "query = \"hello world\"\n",
    "\n",
    "# Embed and get sequence length\n",
    "tensor1, len1 = triplet_dataset.embed_text(query, triplet_dataset.query_max_len)\n",
    "tensor2, len2 = triplet_dataset.embed_text(query, triplet_dataset.query_max_len)\n",
    "\n",
    "# Add batch dimension\n",
    "tensor1 = tensor1.unsqueeze(0).to(device)  # [1, seq_len, emb_dim]\n",
    "tensor2 = tensor2.unsqueeze(0).to(device)\n",
    "len1 = torch.tensor([len1], device=device)\n",
    "len2 = torch.tensor([len2], device=device)\n",
    "\n",
    "# Encode using the query tower\n",
    "vec1 = qryTower(tensor1, len1)  # [1, hidden_dim]\n",
    "vec2 = qryTower(tensor2, len2)\n",
    "\n",
    "# Compute similarity\n",
    "sim = torch.nn.functional.cosine_similarity(vec1, vec2, dim=1)  # [1]\n",
    "print(\"üîÅ Similarit√© entre deux encodages identiques :\", sim.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a77df3",
   "metadata": {},
   "source": [
    "## retrieve most similar documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ea92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docTower.eval()\n",
    "\n",
    "all_doc_texts = train_sn[\"positive_passage\"].tolist()[:500]  # Use fewer if needed\n",
    "\n",
    "doc_vectors = []\n",
    "with torch.no_grad():\n",
    "    for text in all_doc_texts:\n",
    "        doc_tensor, doc_len = triplet_dataset.embed_text(text, triplet_dataset.doc_max_len)\n",
    "        doc_tensor = doc_tensor.unsqueeze(0).to(device)\n",
    "        doc_len = torch.tensor([doc_len], device=device)\n",
    "\n",
    "        doc_vec = docTower(doc_tensor, doc_len)  # [1, hidden_dim]\n",
    "        doc_vectors.append(doc_vec.squeeze(0))\n",
    "\n",
    "doc_matrix = torch.stack(doc_vectors).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a8702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "query = \"how do solar panels work\" \n",
    "\n",
    "qryTower.eval()\n",
    "with torch.no_grad():\n",
    "    qry_tensor, qry_len = triplet_dataset.embed_text(query, triplet_dataset.query_max_len)\n",
    "    qry_tensor = qry_tensor.unsqueeze(0).to(device)\n",
    "    qry_len = torch.tensor([qry_len], device=device)\n",
    "\n",
    "    qry_vec = qryTower(qry_tensor, qry_len)\n",
    "\n",
    "    similarities = cosine_similarity(qry_vec, doc_matrix)  # [num_docs]\n",
    "    top_k = 5\n",
    "    top_indices = similarities.topk(top_k).indices.cpu().numpy()\n",
    "\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(f\"\\nTop {top_k} most relevant documents:\")\n",
    "\n",
    "    for i in top_indices:\n",
    "        print(f\"\\nüî∏ Similarity: {similarities[i].item():.4f}\")\n",
    "        print(all_doc_texts[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
